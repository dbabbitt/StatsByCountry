{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Set up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')\n",
    "\n",
    "from choropleth_utils import ChoroplethUtilities\n",
    "from stats_scraping_utils import StatsScrapingUtilities\n",
    "from storage import Storage\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "s = Storage()\n",
    "ssu = StatsScrapingUtilities(s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\all_countries_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_description_dict = s.load_object('column_description_dict')\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "\n",
    "all_countries_df = s.load_object('all_countries_df').set_index('country_code', drop=True)\n",
    "all_countries_df.country_name = all_countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "s.store_objects(all_countries_df=all_countries_df.reset_index(drop=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Cost of Living Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (6, 8)), (0, (0, 9))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://meric.mo.gov/data/cost-living-data-series'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (52, 10))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "body_opener_str = '</thead>\\n  <tbody>\\n  '\n",
    "head_closer_str = '<th>Misc.</th>\\n    </tr>\\n    '\n",
    "html_str = tables_list[0].to_html().replace(body_opener_str, '').replace(head_closer_str,\n",
    "                                                                         head_closer_str + body_opener_str).replace('th>', 'td>')\n",
    "tables_list = ssu.get_page_tables(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cost_of_living_rank</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_of_living_index</th>\n",
       "      <td>83.099998</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>87.5</td>\n",
       "      <td>88.099998</td>\n",
       "      <td>88.199997</td>\n",
       "      <td>89.199997</td>\n",
       "      <td>89.400002</td>\n",
       "      <td>89.900002</td>\n",
       "      <td>89.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grocery_index</th>\n",
       "      <td>92.300003</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.699997</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.400002</td>\n",
       "      <td>94.099998</td>\n",
       "      <td>93.400002</td>\n",
       "      <td>94.5</td>\n",
       "      <td>92.900002</td>\n",
       "      <td>90.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_index</th>\n",
       "      <td>63.799999</td>\n",
       "      <td>68.800003</td>\n",
       "      <td>68.199997</td>\n",
       "      <td>68.900002</td>\n",
       "      <td>69.5</td>\n",
       "      <td>74.199997</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>77.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utilities_index</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.199997</td>\n",
       "      <td>98.699997</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>91.199997</td>\n",
       "      <td>100.800003</td>\n",
       "      <td>94.099998</td>\n",
       "      <td>96.5</td>\n",
       "      <td>98.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transportation_index</th>\n",
       "      <td>89.099998</td>\n",
       "      <td>90.300003</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.400002</td>\n",
       "      <td>91.400002</td>\n",
       "      <td>97.099998</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>94.5</td>\n",
       "      <td>95.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_index</th>\n",
       "      <td>97.400002</td>\n",
       "      <td>92.900002</td>\n",
       "      <td>102.800003</td>\n",
       "      <td>90.5</td>\n",
       "      <td>99.099998</td>\n",
       "      <td>94.300003</td>\n",
       "      <td>95.400002</td>\n",
       "      <td>91.699997</td>\n",
       "      <td>80.099998</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc_index</th>\n",
       "      <td>92.0</td>\n",
       "      <td>89.699997</td>\n",
       "      <td>90.400002</td>\n",
       "      <td>95.5</td>\n",
       "      <td>95.599998</td>\n",
       "      <td>96.699997</td>\n",
       "      <td>93.800003</td>\n",
       "      <td>93.800003</td>\n",
       "      <td>99.699997</td>\n",
       "      <td>96.599998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0          1           2           3  \\\n",
       "cost_of_living_rank             1          2           3           4   \n",
       "state_name            Mississippi   Oklahoma      Kansas     Alabama   \n",
       "cost_of_living_index    83.099998  84.800003   85.400002        87.5   \n",
       "grocery_index           92.300003       94.0   91.699997        97.0   \n",
       "housing_index           63.799999  68.800003   68.199997   68.900002   \n",
       "utilities_index              90.0  95.199997   98.699997  101.099998   \n",
       "transportation_index    89.099998  90.300003   94.199997        90.0   \n",
       "health_index            97.400002  92.900002  102.800003        90.5   \n",
       "misc_index                   92.0  89.699997   90.400002        95.5   \n",
       "\n",
       "                              4          5           6          7          8  \\\n",
       "cost_of_living_rank           5          6           7          8          9   \n",
       "state_name                 Iowa    Georgia     Indiana  Tennessee   Arkansas   \n",
       "cost_of_living_index  88.099998  88.199997   89.199997  89.400002  89.900002   \n",
       "grocery_index         99.400002  94.099998   93.400002       94.5  92.900002   \n",
       "housing_index              69.5  74.199997   75.900002  80.699997  76.699997   \n",
       "utilities_index       94.800003  91.199997  100.800003  94.099998       96.5   \n",
       "transportation_index  93.400002  91.400002   97.099998  87.900002       94.5   \n",
       "health_index          99.099998  94.300003   95.400002  91.699997  80.099998   \n",
       "misc_index            95.599998  96.699997   93.800003  93.800003  99.699997   \n",
       "\n",
       "                              9  \n",
       "cost_of_living_rank          10  \n",
       "state_name             Michigan  \n",
       "cost_of_living_index  89.900002  \n",
       "grocery_index         90.400002  \n",
       "housing_index         77.800003  \n",
       "utilities_index       98.199997  \n",
       "transportation_index  95.699997  \n",
       "health_index               97.0  \n",
       "misc_index            96.599998  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "# print(us_states_df.columns.tolist())\n",
    "floats_list = ['cost_of_living_index', 'grocery_index', 'housing_index', 'utilities_index', 'transportation_index',\n",
    "                'health_index', 'misc_index']\n",
    "columns_list = ['cost_of_living_rank', 'state_name'] + floats_list\n",
    "us_states_df.columns = ['deleteme'] + columns_list\n",
    "us_states_df = us_states_df[columns_list]\n",
    "for cn in floats_list:\n",
    "    us_states_df[cn] = us_states_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='float')\n",
    "mask_series = us_states_df.state_name.isnull()\n",
    "us_states_df = us_states_df[~mask_series]\n",
    "us_states_df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove DC from the comparison so it doesn't skew the results\n",
    "mask_series = (us_states_df.state_name.isin(['District of Columbia', '***']))\n",
    "us_states_df = us_states_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['District of Columbia']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "print(states_list)\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (137, 8)), (0, (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.numbeo.com/cost-of-living/rankings_by_country.jsp'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>Bermuda</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_of_living_index</th>\n",
       "      <td>141.740005</td>\n",
       "      <td>110.339996</td>\n",
       "      <td>88.269997</td>\n",
       "      <td>87.07</td>\n",
       "      <td>86.589996</td>\n",
       "      <td>85.93</td>\n",
       "      <td>80.379997</td>\n",
       "      <td>79.089996</td>\n",
       "      <td>77.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent_index</th>\n",
       "      <td>98.959999</td>\n",
       "      <td>50.209999</td>\n",
       "      <td>38.41</td>\n",
       "      <td>21.16</td>\n",
       "      <td>35.810001</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>55.369999</td>\n",
       "      <td>65.089996</td>\n",
       "      <td>32.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_of_living_plus_rent_index</th>\n",
       "      <td>121.389999</td>\n",
       "      <td>81.730003</td>\n",
       "      <td>64.550003</td>\n",
       "      <td>55.709999</td>\n",
       "      <td>62.43</td>\n",
       "      <td>59.59</td>\n",
       "      <td>68.480003</td>\n",
       "      <td>72.43</td>\n",
       "      <td>56.189999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groceries Index</th>\n",
       "      <td>142.619995</td>\n",
       "      <td>113.349998</td>\n",
       "      <td>71.919998</td>\n",
       "      <td>81.730003</td>\n",
       "      <td>82.440002</td>\n",
       "      <td>81.309998</td>\n",
       "      <td>64.519997</td>\n",
       "      <td>71.360001</td>\n",
       "      <td>66.449997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurant_price_index</th>\n",
       "      <td>144.740005</td>\n",
       "      <td>104.300003</td>\n",
       "      <td>94.290001</td>\n",
       "      <td>74.5</td>\n",
       "      <td>88.639999</td>\n",
       "      <td>87.589996</td>\n",
       "      <td>89.230003</td>\n",
       "      <td>52.200001</td>\n",
       "      <td>83.919998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_purchasing_power_index</th>\n",
       "      <td>82.339996</td>\n",
       "      <td>116.190002</td>\n",
       "      <td>44.220001</td>\n",
       "      <td>32.619999</td>\n",
       "      <td>82.620003</td>\n",
       "      <td>86.269997</td>\n",
       "      <td>68.720001</td>\n",
       "      <td>94.650002</td>\n",
       "      <td>73.540001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0            1          2          3  \\\n",
       "country_name                       Bermuda  Switzerland    Bahamas   Barbados   \n",
       "cost_of_living_index            141.740005   110.339996  88.269997      87.07   \n",
       "rent_index                       98.959999    50.209999      38.41      21.16   \n",
       "cost_of_living_plus_rent_index  121.389999    81.730003  64.550003  55.709999   \n",
       "groceries Index                 142.619995   113.349998  71.919998  81.730003   \n",
       "restaurant_price_index          144.740005   104.300003  94.290001       74.5   \n",
       "local_purchasing_power_index     82.339996   116.190002  44.220001  32.619999   \n",
       "\n",
       "                                        4          5          6          7  \\\n",
       "country_name                      Iceland     Norway     Jersey  Singapore   \n",
       "cost_of_living_index            86.589996      85.93  80.379997  79.089996   \n",
       "rent_index                      35.810001  30.549999  55.369999  65.089996   \n",
       "cost_of_living_plus_rent_index      62.43      59.59  68.480003      72.43   \n",
       "groceries Index                 82.440002  81.309998  64.519997  71.360001   \n",
       "restaurant_price_index          88.639999  87.589996  89.230003  52.200001   \n",
       "local_purchasing_power_index    82.620003  86.269997  68.720001  94.650002   \n",
       "\n",
       "                                        8  \n",
       "country_name                       Israel  \n",
       "cost_of_living_index            77.279999  \n",
       "rent_index                      32.950001  \n",
       "cost_of_living_plus_rent_index  56.189999  \n",
       "groceries Index                 66.449997  \n",
       "restaurant_price_index          83.919998  \n",
       "local_purchasing_power_index    73.540001  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[1].copy()\n",
    "# print(countries_df.columns.tolist())\n",
    "floats_list = ['cost_of_living_index', 'rent_index', 'cost_of_living_plus_rent_index', 'groceries Index',\n",
    "               'restaurant_price_index', 'local_purchasing_power_index']\n",
    "columns_list = ['country_name'] + floats_list\n",
    "countries_df.columns = ['cost_of_living_rank'] + columns_list\n",
    "for cn in floats_list:\n",
    "    countries_df[cn] = countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn], errors='coerce', downcast='float')\n",
    "mask_series = countries_df.country_name.isnull()\n",
    "countries_df = countries_df[~mask_series][columns_list]\n",
    "# countries_df.country_name = countries_df.country_name.map(lambda x: str(x).split('*')[0].strip())\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan', 'American Samoa', 'Andorra', 'Angola', 'Anguilla', 'Antarctica', 'Antigua & Barbuda', 'Aruba', 'Benin', 'Bhutan', 'Bonaire, Sint Eustatius & Saba', 'Bouvet Island', 'British Indian Ocean Territory', 'British Virgin Islands', 'Burkina Faso', 'Burundi', 'Cayman Islands', 'Central African Republic', 'Chad', 'Christmas Island', 'Cocos (Keeling) Islands', 'Comoros', 'Cook Islands', 'Curaçao', \"Côte d'Ivoire\", 'DRC', 'Djibouti', 'Dominica', 'Equatorial Guinea', 'Eritrea', 'Eswatini', 'Falkland Islands (Malvinas)', 'Faroe Islands', 'Federated States of Micronesia', 'French Guiana', 'French Polynesia', 'French Southern Territories', 'Gabon', 'Gambia', 'Gibraltar', 'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guinea', 'Guinea-Bissau', 'Haiti', 'Heard Island and McDonald Islands', 'Holy See', 'Isle of Man', 'Ivory Coast', 'Kiribati', 'Kosovo (Disputed Territory)', 'Laos', 'Lesotho', 'Liberia', 'Liechtenstein', 'Madagascar', 'Malawi', 'Mali', 'Marshall Islands', 'Martinique', 'Mauritania', 'Mayotte', 'Monaco', 'Montserrat', 'Mozambique', 'Nauru', 'New Caledonia', 'Niger', 'Niue', 'Norfolk Island', 'North Korea', 'Northern Mariana Islands', 'Palau', 'Papua New Guinea', 'Pitcairn', 'Réunion', 'Saint Helena, Ascension & Tristan da Cunha', 'Samoa', 'San Marino', 'Senegal', 'Seychelles', 'Sierra Leone', 'Sint Maarten', 'Solomon Islands', 'South Georgia and the South Sandwich Islands', 'South Sudan', 'St. Barthélemy', 'St. Kitts & Nevis', 'St. Lucia', 'St. Martin', 'St. Pierre & Miquelon', 'St. Vincent & Grenadines', 'Sudan', 'Suriname', 'Svalbard and Jan Mayen', 'São Tomé & Príncipe', 'Tajikistan', 'Timor-Leste', 'Togo', 'Tokelau', 'Tonga', 'Turkmenistan', 'Turks & Caicos Islands', 'Tuvalu', 'US Virgin Islands', 'United States Minor Outlying Islands', 'Vanuatu', 'Wallis & Futuna', 'Western Sahara', 'Yemen', 'Zambia', 'Åland Islands']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Gambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Malawi</td>\n",
       "      <td>Mali</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Greenland</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Togo</td>\n",
       "      <td>Tonga</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Niger</td>\n",
       "      <td>Niue</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Guinea</td>\n",
       "      <td>Guinea-Bissau</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>South Sudan</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  first_item        second_item  max_similarity\n",
       "38                    Gambia             Zambia        0.833333\n",
       "58                    Malawi               Mali        0.800000\n",
       "13    British Virgin Islands  US Virgin Islands        0.769231\n",
       "22              Cook Islands     Norfolk Island        0.769231\n",
       "40                 Greenland            Grenada        0.750000\n",
       "16            Cayman Islands      Åland Islands        0.740741\n",
       "84              Sint Maarten         St. Martin        0.727273\n",
       "85           Solomon Islands      Åland Islands        0.714286\n",
       "3                     Angola           Anguilla        0.714286\n",
       "80                San Marino         St. Martin        0.700000\n",
       "11             Bouvet Island      Faroe Islands        0.692308\n",
       "32             Faroe Islands      Åland Islands        0.692308\n",
       "100                     Togo              Tonga        0.666667\n",
       "69                     Niger               Niue        0.666667\n",
       "98                Tajikistan       Turkmenistan        0.636364\n",
       "44                    Guinea      Guinea-Bissau        0.631579\n",
       "20   Cocos (Keeling) Islands       Cook Islands        0.628571\n",
       "87               South Sudan              Sudan        0.625000\n",
       "71            Norfolk Island    Solomon Islands        0.620690\n",
       "60          Marshall Islands      Åland Islands        0.620690\n",
       "34             French Guiana   French Polynesia        0.620690\n",
       "2                    Andorra             Angola        0.615385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "if countries_list:\n",
    "    print(countries_list)\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_of_living_index</th>\n",
       "      <td>69.919998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent_index</th>\n",
       "      <td>46.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_of_living_plus_rent_index</th>\n",
       "      <td>58.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groceries Index</th>\n",
       "      <td>70.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurant_price_index</th>\n",
       "      <td>65.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_purchasing_power_index</th>\n",
       "      <td>99.879997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_cost_of_living_index</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        14\n",
       "country_name                           USA\n",
       "cost_of_living_index             69.919998\n",
       "rent_index                       46.860001\n",
       "cost_of_living_plus_rent_index   58.950001\n",
       "groceries Index                  70.059998\n",
       "restaurant_price_index               65.75\n",
       "local_purchasing_power_index     99.879997\n",
       "normalized_cost_of_living_index      100.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Normalize the index so that the US is 100\n",
    "mask_series = (countries_df.country_name == 'USA')\n",
    "cost_of_living_index = countries_df[mask_series].cost_of_living_index.squeeze()\n",
    "countries_df['normalized_cost_of_living_index'] = countries_df.cost_of_living_index.map(lambda x: 100*x/cost_of_living_index)\n",
    "mask_series = (countries_df.country_name == 'USA')\n",
    "countries_df[mask_series].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Albania (48.05) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Algeria (35.87) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Argentina (45.95) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Armenia (55.72) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Australia (103.36) is close to the normalized cost of living index of Nevada (103.10)\n",
      "Austria (91.69) is close to the normalized cost of living index of Illinois (91.70)\n",
      "Azerbaijan (40.52) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Bahamas (126.24) is close to the normalized cost of living index of Maryland (126.40)\n",
      "Bahrain (77) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Bangladesh (41.88) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Barbados (124.53) is close to the normalized cost of living index of Oregon (125.20)\n",
      "Belarus (37.74) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Belgium (89.82) is close to the normalized cost of living index of Arkansas (89.90)\n",
      "Belize (70.87) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Bermuda (202.72) is close to the normalized cost of living index of Hawaii (192.70)\n",
      "Bolivia (46.58) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Bosnia & Herzegovina (46.11) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Botswana (52.23) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Brazil (49.79) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Brunei (62.03) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Bulgaria (53.75) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Cambodia (65.40) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Cameroon (46.48) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Canada (98.37) is close to the normalized cost of living index of Pennsylvania (97.50)\n",
      "Chile (53.15) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "China (57.65) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Colombia (36.08) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Costa Rica (62.43) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Croatia (62.56) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Cuba (77.26) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Cyprus (75.06) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Czechia (63.40) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Denmark (104.53) is close to the normalized cost of living index of Montana (104.40)\n",
      "Dominican Republic (60.03) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Ecuador (51.10) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Egypt (37.57) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "El Salvador (61.41) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Estonia (70.75) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Ethiopia (59.70) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Fiji (56.31) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Finland (91.18) is close to the normalized cost of living index of Ohio (90.80)\n",
      "France (93.75) is close to the normalized cost of living index of New Mexico (93.90)\n",
      "Georgia (49.84) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Germany (85.27) is close to the normalized cost of living index of Kansas (85.40)\n",
      "Ghana (42.88) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Greece (71.84) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Guatemala (59.12) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Guernsey (101.37) is close to the normalized cost of living index of Colorado (102.40)\n",
      "Guyana (67.03) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Honduras (55.65) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Hong Kong (109.48) is close to the normalized cost of living index of Arizona (106.70)\n",
      "Hungary (49.54) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Iceland (123.84) is close to the normalized cost of living index of Oregon (125.20)\n",
      "India (34.17) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Indonesia (46.05) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Iran (52.19) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Iraq (45.49) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Ireland (95.44) is close to the normalized cost of living index of Wisconsin (95.50)\n",
      "Israel (110.53) is close to the normalized cost of living index of Rhode Island (112.80)\n",
      "Italy (83.62) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Jamaica (72.58) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Japan (89.77) is close to the normalized cost of living index of Arkansas (89.90)\n",
      "Jersey (114.96) is close to the normalized cost of living index of Maine (115.10)\n",
      "Jordan (67.98) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Kazakhstan (37.83) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Kenya (47.71) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Kuwait (65.79) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Kyrgyzstan (36.94) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Latvia (64.66) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Lebanon (98.01) is close to the normalized cost of living index of Pennsylvania (97.50)\n",
      "Libya (35.18) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Lithuania (61.64) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Luxembourg (103.19) is close to the normalized cost of living index of Nevada (103.10)\n",
      "Macau (97.81) is close to the normalized cost of living index of Pennsylvania (97.50)\n",
      "Malaysia (49.21) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Maldives (77.93) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Malta (82.54) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Mauritius (58.18) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Mexico (50.26) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Moldova (41.36) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Mongolia (48.18) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Montenegro (49.69) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Morocco (42.49) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Myanmar (47.40) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Namibia (50.90) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Nepal (37.44) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Netherlands (96.84) is close to the normalized cost of living index of North Dakota (96.80)\n",
      "New Zealand (98.63) is close to the normalized cost of living index of Idaho (99.40)\n",
      "Nicaragua (53.16) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Nigeria (42.92) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "North Macedonia (40.78) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Norway (122.90) is close to the normalized cost of living index of Oregon (125.20)\n",
      "Oman (68.81) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Pakistan (25.43) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Palestine (71.87) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Panama (69.01) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Paraguay (43.25) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Peru (43.96) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Philippines (48.08) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Poland (50.14) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Portugal (60.33) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Puerto Rico (92.36) is close to the normalized cost of living index of Texas (92.10)\n",
      "Qatar (86.61) is close to the normalized cost of living index of Alabama (87.50)\n",
      "Romania (49.96) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Russia (68.75) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Rwanda (44.08) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Saudi Arabia (72.01) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Serbia (47.70) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Singapore (113.11) is close to the normalized cost of living index of New Jersey (112.90)\n",
      "Slovakia (58.68) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Slovenia (67.65) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Somalia (45.65) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "South Africa (54.26) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "South Korea (95.75) is close to the normalized cost of living index of Wisconsin (95.50)\n",
      "Spain (67.95) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Sri Lanka (32.05) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Sweden (88.34) is close to the normalized cost of living index of Georgia (88.20)\n",
      "Switzerland (157.81) is close to the normalized cost of living index of New York (152.10)\n",
      "Syria (36.93) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Taiwan (80.02) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Tanzania (43.09) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Thailand (55.23) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Trinidad & Tobago (76.34) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Tunisia (36.44) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Turkiye (40.59) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "UAE (82.97) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "UK (86.41) is close to the normalized cost of living index of Kansas (85.40)\n",
      "USA (100) is close to the normalized cost of living index of Idaho (99.40)\n",
      "Uganda (44.92) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Ukraine (43.91) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Uruguay (84.45) is close to the normalized cost of living index of Oklahoma (84.80)\n",
      "Uzbekistan (37.61) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Venezuela (59.74) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Vietnam (50.90) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "Zimbabwe (60.84) is close to the normalized cost of living index of Mississippi (83.10)\n",
      "\n",
      "Alabama (87.50) is close to the Cost of Living Index (2022) of Sweden (88.34)\n",
      "Alaska (127.30) is close to the Cost of Living Index (2022) of Bahamas (126.24)\n",
      "Arizona (106.70) is close to the Cost of Living Index (2022) of Denmark (104.53)\n",
      "Arkansas (89.90) is close to the Cost of Living Index (2022) of Belgium (89.82)\n",
      "California (139.70) is close to the Cost of Living Index (2022) of Bahamas (126.24)\n",
      "Colorado (102.40) is close to the Cost of Living Index (2022) of Luxembourg (103.19)\n",
      "Connecticut (118.90) is close to the Cost of Living Index (2022) of Jersey (114.96)\n",
      "Delaware (105.80) is close to the Cost of Living Index (2022) of Denmark (104.53)\n",
      "Florida (102.60) is close to the Cost of Living Index (2022) of Luxembourg (103.19)\n",
      "Georgia (88.20) is close to the Cost of Living Index (2022) of Sweden (88.34)\n",
      "Hawaii (192.70) is close to the Cost of Living Index (2022) of Bermuda (202.72)\n",
      "Idaho (99.40) is close to the Cost of Living Index (2022) of USA (100)\n",
      "Illinois (91.70) is close to the Cost of Living Index (2022) of Austria (91.69)\n",
      "Indiana (89.20) is close to the Cost of Living Index (2022) of Japan (89.77)\n",
      "Iowa (88.10) is close to the Cost of Living Index (2022) of Sweden (88.34)\n",
      "Kansas (85.40) is close to the Cost of Living Index (2022) of Germany (85.27)\n",
      "Kentucky (93.60) is close to the Cost of Living Index (2022) of France (93.75)\n",
      "Louisiana (93.30) is close to the Cost of Living Index (2022) of France (93.75)\n",
      "Maine (115.10) is close to the Cost of Living Index (2022) of Jersey (114.96)\n",
      "Maryland (126.40) is close to the Cost of Living Index (2022) of Bahamas (126.24)\n",
      "Massachusetts (130.20) is close to the Cost of Living Index (2022) of Bahamas (126.24)\n",
      "Michigan (89.90) is close to the Cost of Living Index (2022) of Belgium (89.82)\n",
      "Minnesota (97.20) is close to the Cost of Living Index (2022) of Netherlands (96.84)\n",
      "Mississippi (83.10) is close to the Cost of Living Index (2022) of UAE (82.97)\n",
      "Missouri (90.50) is close to the Cost of Living Index (2022) of Finland (91.18)\n",
      "Montana (104.40) is close to the Cost of Living Index (2022) of Denmark (104.53)\n",
      "Nebraska (91.80) is close to the Cost of Living Index (2022) of Austria (91.69)\n",
      "Nevada (103.10) is close to the Cost of Living Index (2022) of Luxembourg (103.19)\n",
      "New Hampshire (117.40) is close to the Cost of Living Index (2022) of Jersey (114.96)\n",
      "New Jersey (112.90) is close to the Cost of Living Index (2022) of Singapore (113.11)\n",
      "New Mexico (93.90) is close to the Cost of Living Index (2022) of France (93.75)\n",
      "New York (152.10) is close to the Cost of Living Index (2022) of Switzerland (157.81)\n",
      "North Carolina (95) is close to the Cost of Living Index (2022) of Ireland (95.44)\n",
      "North Dakota (96.80) is close to the Cost of Living Index (2022) of Netherlands (96.84)\n",
      "Ohio (90.80) is close to the Cost of Living Index (2022) of Finland (91.18)\n",
      "Oklahoma (84.80) is close to the Cost of Living Index (2022) of Uruguay (84.45)\n",
      "Oregon (125.20) is close to the Cost of Living Index (2022) of Barbados (124.53)\n",
      "Pennsylvania (97.50) is close to the Cost of Living Index (2022) of Macau (97.81)\n",
      "Rhode Island (112.80) is close to the Cost of Living Index (2022) of Singapore (113.11)\n",
      "South Carolina (93.90) is close to the Cost of Living Index (2022) of France (93.75)\n",
      "South Dakota (95.20) is close to the Cost of Living Index (2022) of Ireland (95.44)\n",
      "Tennessee (89.40) is close to the Cost of Living Index (2022) of Japan (89.77)\n",
      "Texas (92.10) is close to the Cost of Living Index (2022) of Puerto Rico (92.36)\n",
      "Utah (104.20) is close to the Cost of Living Index (2022) of Denmark (104.53)\n",
      "Vermont (116.90) is close to the Cost of Living Index (2022) of Jersey (114.96)\n",
      "Virginia (102.70) is close to the Cost of Living Index (2022) of Luxembourg (103.19)\n",
      "Washington (113.90) is close to the Cost of Living Index (2022) of Singapore (113.11)\n",
      "West Virginia (90.50) is close to the Cost of Living Index (2022) of Finland (91.18)\n",
      "Wisconsin (95.50) is close to the Cost of Living Index (2022) of Ireland (95.44)\n",
      "Wyoming (93.90) is close to the Cost of Living Index (2022) of France (93.75)\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\us_stats_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\column_description_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_Cost_of_Living'\n",
    "states_target_column_name = 'cost_of_living_index'\n",
    "mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'normalized_cost_of_living_index', us_states_df,\n",
    "                              st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='Cost of Living Index (2022)',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_cost_of_living_index_Country_Equivalent_Cost_of_Living.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(\n",
    "    numeric_column_name=states_target_column_name, string_column_name=equivalence_column_name,\n",
    "    one_country_df=ssu.us_stats_df, cmap='summer')\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Income Inequality Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://worldpopulationreview.com/state-rankings/income-inequality-by-state'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New York</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gini_coefficient</th>\n",
       "      <td>46.209999</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.02</td>\n",
       "      <td>44.200001</td>\n",
       "      <td>46.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             25       4         0          40     23\n",
       "state_name        West Virginia  Florida  New York   Nebraska   Ohio\n",
       "gini_coefficient      46.209999     49.0     51.02  44.200001  46.41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "# print(us_states_df.columns.tolist())\n",
    "us_states_df.columns = ['state_name', 'gini_coefficient']\n",
    "for cn in ['gini_coefficient']:\n",
    "    us_states_df[cn] = us_states_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='float')\n",
    "mask_series = us_states_df.state_name.isnull()\n",
    "us_states_df = us_states_df[~mask_series]\n",
    "us_states_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (us_states_df.state_name == 'District of Columbia')\n",
    "us_states_df = us_states_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['District of Columbia']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "print(states_list)\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\income_inequality_us_states_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(income_inequality_us_states_df=us_states_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Suriname</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>São Tomé &amp; Príncipe</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>Eswatini</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gini_index</th>\n",
       "      <td>63.0</td>\n",
       "      <td>59.099998</td>\n",
       "      <td>57.900002</td>\n",
       "      <td>57.099998</td>\n",
       "      <td>56.299999</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>54.599998</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_population_2022</th>\n",
       "      <td>59893885</td>\n",
       "      <td>2567012</td>\n",
       "      <td>618040</td>\n",
       "      <td>20017675</td>\n",
       "      <td>227380</td>\n",
       "      <td>5579144</td>\n",
       "      <td>1201670</td>\n",
       "      <td>32969518</td>\n",
       "      <td>215313498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0          1          2          3  \\\n",
       "country_name             South Africa    Namibia   Suriname     Zambia   \n",
       "gini_index                       63.0  59.099998  57.900002  57.099998   \n",
       "country_population_2022      59893885    2567012     618040   20017675   \n",
       "\n",
       "                                           4                         5  \\\n",
       "country_name             São Tomé & Príncipe  Central African Republic   \n",
       "gini_index                         56.299999                 56.200001   \n",
       "country_population_2022               227380                   5579144   \n",
       "\n",
       "                                 6           7          8  \n",
       "country_name              Eswatini  Mozambique     Brazil  \n",
       "gini_index               54.599998        54.0  53.400002  \n",
       "country_population_2022    1201670    32969518  215313498  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if s.pickle_exists('income_inequality_countries_df'):\n",
    "    countries_df = s.load_object('income_inequality_countries_df')\n",
    "else:\n",
    "    driver = ssu.get_driver()\n",
    "    tables_list = ssu.get_page_tables('https://worldpopulationreview.com/country-rankings/wealth-inequality-by-country', driver=driver)\n",
    "    driver.close()\n",
    "    countries_df = tables_list[0].copy()\n",
    "    # print(countries_df.columns.tolist())\n",
    "    countries_df.columns = ['country_name', 'gini_index', 'country_population_2022']\n",
    "    for cn in ['gini_index']:\n",
    "        countries_df[cn] = pd.to_numeric(countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x))), errors='coerce', downcast='float')\n",
    "    mask_series = countries_df.country_name.isnull()\n",
    "    countries_df = countries_df[~mask_series]\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Greenland</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 first_item        second_item  max_similarity\n",
       "14   British Virgin Islands  US Virgin Islands        0.769231\n",
       "20             Cook Islands     Norfolk Island        0.769231\n",
       "34                Greenland            Grenada        0.750000\n",
       "17           Cayman Islands      Åland Islands        0.740741\n",
       "72             Sint Maarten         St. Martin        0.727273\n",
       "38                 Guernsey             Jersey        0.714286\n",
       "69               San Marino         St. Martin        0.700000\n",
       "12            Bouvet Island      Faroe Islands        0.692308\n",
       "28            Faroe Islands      Åland Islands        0.692308\n",
       "6                     Aruba               Cuba        0.666667\n",
       "19  Cocos (Keeling) Islands       Cook Islands        0.628571\n",
       "30            French Guiana   French Polynesia        0.620690\n",
       "49         Marshall Islands      Åland Islands        0.620690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\income_inequality_countries_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(income_inequality_countries_df=countries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_Income_Inequality'\n",
    "states_target_column_name = 'gini_coefficient'\n",
    "# mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "mask_series = countries_df.country_name.isin(ssu.oecd_countries_list)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'gini_index', us_states_df, st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='Gini Coefficient (2022)',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_gini_coefficient_Country_Equivalent_Income_Inequality.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(\n",
    "    numeric_column_name=states_target_column_name, string_column_name=equivalence_column_name,\n",
    "    one_country_df=ssu.us_stats_df, cmap='summer')\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country CO<sub>2</sub> Emissions Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.bts.gov/browse-statistical-products-and-data/state-transportation-statistics/energy-consumption-and-co2'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 6)\n",
      "5166.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>co2_emissions_mmt</th>\n",
       "      <th>co2_emissions_mmt_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>51.9</td>\n",
       "      <td>0.008616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.046370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>67.8</td>\n",
       "      <td>0.022687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>69.2</td>\n",
       "      <td>0.013781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>152.7</td>\n",
       "      <td>0.015311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state_name  co2_emissions_mmt  co2_emissions_mmt_per_capita\n",
       "1758        Maryland               51.9                      0.008616\n",
       "162           Alaska               34.3                      0.046370\n",
       "2094     Mississippi               67.8                      0.022687\n",
       "3438  South Carolina               69.2                      0.013781\n",
       "1926        Michigan              152.7                      0.015311"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = s.load_csv('Energy_Consumption_and_CO2_Emissions_by_us_state')\n",
    "# print(us_states_df.columns.tolist())\n",
    "us_states_df.columns = ['state_name', 'measure_str', 'sector_str', 'measure_year', 'pivot_list', 'co2_emissions_mmt']\n",
    "mask_series = us_states_df.state_name.isin(ssu.us_states_list) & (us_states_df.sector_str == 'Total') & (us_states_df.measure_year == 2017)\n",
    "print(us_states_df[mask_series].shape)\n",
    "columns_list = ['state_name', 'co2_emissions_mmt']\n",
    "us_states_df = us_states_df[mask_series][columns_list]\n",
    "print(us_states_df.co2_emissions_mmt.sum())\n",
    "\n",
    "url = 'https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/national/totals/nst-est2019-alldata.csv'\n",
    "POPULATION_DICT = pd.read_csv(url, encoding=s.encoding_type).set_index('NAME').POPESTIMATE2017.to_dict()\n",
    "def f(row_series):\n",
    "    state_name = row_series.state_name\n",
    "    co2_emissions_mmt = row_series.co2_emissions_mmt\n",
    "    \n",
    "    return 1_000*co2_emissions_mmt/POPULATION_DICT[state_name]\n",
    "us_states_df['co2_emissions_mmt_per_capita'] = us_states_df.apply(f, axis='columns')\n",
    "\n",
    "us_states_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (us_states_df.state_name == 'District of Columbia')\n",
    "us_states_df = us_states_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the FireFox driver\n",
      "[(0, (210, 6))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = ssu.get_driver()\n",
    "tables_list = ssu.get_page_tables('https://worldpopulationreview.com/country-rankings/carbon-footprint-by-country', driver=driver)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>China</td>\n",
       "      <td>United States</td>\n",
       "      <td>India</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Germany</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2_emissions_mt_2020</th>\n",
       "      <td>11680.419922</td>\n",
       "      <td>4535.299805</td>\n",
       "      <td>2411.72998</td>\n",
       "      <td>1674.22998</td>\n",
       "      <td>1061.77002</td>\n",
       "      <td>690.23999</td>\n",
       "      <td>636.880005</td>\n",
       "      <td>621.469971</td>\n",
       "      <td>588.809998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2_emissions_mt_2017</th>\n",
       "      <td>10877.219727</td>\n",
       "      <td>5107.390137</td>\n",
       "      <td>2454.77002</td>\n",
       "      <td>1764.869995</td>\n",
       "      <td>1320.780029</td>\n",
       "      <td>671.450012</td>\n",
       "      <td>796.530029</td>\n",
       "      <td>673.320007</td>\n",
       "      <td>638.76001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2_emissions_per_capita_2020</th>\n",
       "      <td>8.2</td>\n",
       "      <td>13.68</td>\n",
       "      <td>1.74</td>\n",
       "      <td>11.64</td>\n",
       "      <td>8.39</td>\n",
       "      <td>8.26</td>\n",
       "      <td>7.72</td>\n",
       "      <td>12.07</td>\n",
       "      <td>16.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2_emissions_per_capita_2017</th>\n",
       "      <td>7.7</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>13.2</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_population_2022</th>\n",
       "      <td>1425887337</td>\n",
       "      <td>338289857</td>\n",
       "      <td>1417173173</td>\n",
       "      <td>144713314</td>\n",
       "      <td>123951692</td>\n",
       "      <td>88550570</td>\n",
       "      <td>83369843</td>\n",
       "      <td>51815810</td>\n",
       "      <td>36408820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0              1           2  \\\n",
       "country_name                          China  United States       India   \n",
       "co2_emissions_mt_2020          11680.419922    4535.299805  2411.72998   \n",
       "co2_emissions_mt_2017          10877.219727    5107.390137  2454.77002   \n",
       "co2_emissions_per_capita_2020           8.2          13.68        1.74   \n",
       "co2_emissions_per_capita_2017           7.7           15.7         1.8   \n",
       "country_population_2022          1425887337      338289857  1417173173   \n",
       "\n",
       "                                         3            4           5  \\\n",
       "country_name                        Russia        Japan        Iran   \n",
       "co2_emissions_mt_2020           1674.22998   1061.77002   690.23999   \n",
       "co2_emissions_mt_2017          1764.869995  1320.780029  671.450012   \n",
       "co2_emissions_per_capita_2020        11.64         8.39        8.26   \n",
       "co2_emissions_per_capita_2017         12.3         10.4         8.3   \n",
       "country_population_2022          144713314    123951692    88550570   \n",
       "\n",
       "                                        6            7             8  \n",
       "country_name                      Germany  South Korea  Saudi Arabia  \n",
       "co2_emissions_mt_2020          636.880005   621.469971    588.809998  \n",
       "co2_emissions_mt_2017          796.530029   673.320007     638.76001  \n",
       "co2_emissions_per_capita_2020        7.72        12.07     16.959999  \n",
       "co2_emissions_per_capita_2017         9.7         13.2          19.4  \n",
       "country_population_2022          83369843     51815810      36408820  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[0].copy()\n",
    "# print(countries_df.columns.tolist())\n",
    "countries_df.columns = ['country_name', 'co2_emissions_mt_2020',  'co2_emissions_mt_2017',\n",
    "                        'co2_emissions_per_capita_2020', 'co2_emissions_per_capita_2017', 'country_population_2022']\n",
    "for cn in ['co2_emissions_mt_2020', 'co2_emissions_mt_2017', 'co2_emissions_per_capita_2020', 'co2_emissions_per_capita_2017']:\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x))), errors='coerce', downcast='float')\n",
    "mask_series = countries_df.country_name.isnull()\n",
    "countries_df = countries_df[~mask_series]\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: str(x).split('*')[0].strip())\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Falkland Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          first_item    second_item  max_similarity\n",
       "10  Falkland Islands  Åland Islands        0.827586\n",
       "32      Sint Maarten     St. Martin        0.727273\n",
       "15          Guernsey         Jersey        0.714286\n",
       "21  Marshall Islands  Åland Islands        0.620690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_CO2_Emissions'\n",
    "states_target_column_name = 'co2_emissions_mmt'\n",
    "mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'co2_emissions_mt_2017', us_states_df, st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='CO2 Emissions in Millions of Metric Tons (2017)',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_co2_emissions_mmt_Country_Equivalent_CO2_Emissions.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(\n",
    "    numeric_column_name=states_target_column_name, string_column_name=equivalence_column_name,\n",
    "    one_country_df=ssu.us_stats_df, cmap='summer')\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Suicide Rate Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.cdc.gov/nchs/pressroom/sosmap/suicide-mortality/suicide.htm'\n",
    "tables_list = ssu.get_page_tables(url)\n",
    "if not tables_list:\n",
    "    tables_list = [pd.read_csv('../data/csv/suicide_2019.csv', encoding=s.encoding_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YEAR', 'STATE', 'RATE', 'DEATHS', 'URL']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>82</th>\n",
       "      <th>71</th>\n",
       "      <th>54</th>\n",
       "      <th>67</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source_year</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_abbreviation</th>\n",
       "      <td>NC</td>\n",
       "      <td>MI</td>\n",
       "      <td>CA</td>\n",
       "      <td>LA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide_rate</th>\n",
       "      <td>12.5</td>\n",
       "      <td>14.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_count</th>\n",
       "      <td>1358</td>\n",
       "      <td>1472</td>\n",
       "      <td>4436</td>\n",
       "      <td>704</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_url</th>\n",
       "      <td>https://www.cdc.gov/nchs/pressroom/states/nort...</td>\n",
       "      <td>https://www.cdc.gov/nchs/pressroom/states/mich...</td>\n",
       "      <td>https://www.cdc.gov/nchs/pressroom/states/cali...</td>\n",
       "      <td>https://www.cdc.gov/nchs/pressroom/states/loui...</td>\n",
       "      <td>https://www.cdc.gov/nchs/pressroom/states/dela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>California</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   82  \\\n",
       "source_year                                                      2019   \n",
       "state_abbreviation                                                 NC   \n",
       "suicide_rate                                                     12.5   \n",
       "body_count                                                       1358   \n",
       "source_url          https://www.cdc.gov/nchs/pressroom/states/nort...   \n",
       "state_name                                             North Carolina   \n",
       "\n",
       "                                                                   71  \\\n",
       "source_year                                                      2019   \n",
       "state_abbreviation                                                 MI   \n",
       "suicide_rate                                                     14.3   \n",
       "body_count                                                       1472   \n",
       "source_url          https://www.cdc.gov/nchs/pressroom/states/mich...   \n",
       "state_name                                                   Michigan   \n",
       "\n",
       "                                                                   54  \\\n",
       "source_year                                                      2019   \n",
       "state_abbreviation                                                 CA   \n",
       "suicide_rate                                                     10.7   \n",
       "body_count                                                       4436   \n",
       "source_url          https://www.cdc.gov/nchs/pressroom/states/cali...   \n",
       "state_name                                                 California   \n",
       "\n",
       "                                                                   67  \\\n",
       "source_year                                                      2019   \n",
       "state_abbreviation                                                 LA   \n",
       "suicide_rate                                                     15.0   \n",
       "body_count                                                        704   \n",
       "source_url          https://www.cdc.gov/nchs/pressroom/states/loui...   \n",
       "state_name                                                  Louisiana   \n",
       "\n",
       "                                                                   57  \n",
       "source_year                                                      2019  \n",
       "state_abbreviation                                                 DE  \n",
       "suicide_rate                                                     11.3  \n",
       "body_count                                                        111  \n",
       "source_url          https://www.cdc.gov/nchs/pressroom/states/dela...  \n",
       "state_name                                                   Delaware  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "print(us_states_df.columns.tolist())\n",
    "us_states_df.columns = ['source_year', 'state_abbreviation', 'suicide_rate', 'body_count', 'source_url']\n",
    "for cn in ['source_year', 'suicide_rate', 'body_count']:\n",
    "    us_states_df[cn] = us_states_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='integer')\n",
    "abbreviation_dict = {v: k for k, v in ssu.us_states_abbreviation_dict.items()}\n",
    "mask_series = us_states_df.state_abbreviation.isnull()\n",
    "us_states_df = us_states_df[~mask_series]\n",
    "us_states_df['state_name'] = us_states_df.state_abbreviation.map(lambda x: abbreviation_dict.get(x, x))\n",
    "mask_series = (us_states_df.source_year == 2019)\n",
    "us_states_df = us_states_df[mask_series]\n",
    "us_states_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['District of Columbia']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "print(states_list)\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (190, 4)), (2, (184, 21)), (3, (184, 21)), (4, (184, 21)), (6, (112, 5)), (7, (12, 2)), (0, (10, 1)), (9, (8, 2)), (8, (6, 2)), (5, (5, 5))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_suicide_rate'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Country', 'All', 'Male', 'Female']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide_rate</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_suicide_rate</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_suicide_rate</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0        1        2          3  \\\n",
       "country_name         Afghanistan  Albania  Algeria     Angola   \n",
       "suicide_rate                 6.0      3.7      2.6       12.6   \n",
       "male_suicide_rate            6.2      5.3      3.3  21.700001   \n",
       "female_suicide_rate          5.7      2.2      1.9        4.7   \n",
       "\n",
       "                                       4          5        6          7  \\\n",
       "country_name         Antigua and Barbuda  Argentina  Armenia  Australia   \n",
       "suicide_rate                         0.3        8.1      2.7       11.3   \n",
       "male_suicide_rate                    0.0       13.5      4.9       17.0   \n",
       "female_suicide_rate                  0.6        3.3      1.0        5.6   \n",
       "\n",
       "                           8  \n",
       "country_name         Austria  \n",
       "suicide_rate            10.4  \n",
       "male_suicide_rate       16.6  \n",
       "female_suicide_rate      4.6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[1].copy()\n",
    "print(countries_df.columns.tolist())\n",
    "columns_list = ['suicide_rate', 'male_suicide_rate', 'female_suicide_rate']\n",
    "countries_df.columns = ['country_name'] + columns_list\n",
    "for cn in columns_list:\n",
    "    countries_df[cn] = countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn], errors='coerce', downcast='float')\n",
    "mask_series = countries_df.country_name.isnull()\n",
    "countries_df = countries_df[~mask_series]\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: str(x).split('*')[0].strip())\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Africa', 'American Samoa', 'Americas', 'Andorra', 'Anguilla', 'Antarctica', 'Aruba', 'Bermuda', 'Bonaire, Sint Eustatius & Saba', 'Bouvet Island', 'British Indian Ocean Territory', 'British Virgin Islands', 'Cape Verde', 'Cayman Islands', 'Christmas Island', 'Cocos (Keeling) Islands', 'Cook Islands', 'Curaçao', \"Côte d'Ivoire\", 'Dominica', 'East Timor', 'Eastern Mediterranean', 'Europe', 'Falkland Islands (Malvinas)', 'Faroe Islands', 'Federated States of Micronesia', 'French Guiana', 'French Polynesia', 'French Southern Territories', 'Gibraltar', 'Global', 'Greenland', 'Guadeloupe', 'Guam', 'Guernsey', 'Heard Island and McDonald Islands', 'Holy See', 'Hong Kong', 'Isle of Man', 'Ivory Coast', 'Jersey', 'Liechtenstein', 'Macau', 'Marshall Islands', 'Martinique', 'Mayotte', 'Micronesia', 'Monaco', 'Montserrat', 'Nauru', 'New Caledonia', 'Niue', 'Norfolk Island', 'Northern Mariana Islands', 'Palau', 'Palestine', 'Pitcairn', 'Puerto Rico', 'ROC', 'Réunion', 'Saint Helena, Ascension & Tristan da Cunha', 'San Marino', 'Sint Maarten', 'South Georgia and the South Sandwich Islands', 'South-East Asia', 'St. Barthélemy', 'St. Kitts & Nevis', 'St. Martin', 'St. Pierre & Miquelon', 'Svalbard and Jan Mayen', 'Taiwan', 'Timor-Leste', 'Tokelau', 'Turks & Caicos Islands', 'Tuvalu', 'US Virgin Islands', 'United States Minor Outlying Islands', 'Wallis & Futuna', 'Western Pacific', 'Western Sahara', 'Åland Islands']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Americas</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>Americas</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Western Pacific</td>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 first_item        second_item  max_similarity\n",
       "11   British Virgin Islands  US Virgin Islands        0.769231\n",
       "16             Cook Islands     Norfolk Island        0.769231\n",
       "13           Cayman Islands      Åland Islands        0.740741\n",
       "62             Sint Maarten         St. Martin        0.727273\n",
       "0                    Africa           Americas        0.714286\n",
       "34                 Guernsey             Jersey        0.714286\n",
       "61               San Marino         St. Martin        0.700000\n",
       "9             Bouvet Island      Faroe Islands        0.692308\n",
       "24            Faroe Islands      Åland Islands        0.692308\n",
       "1            American Samoa           Americas        0.636364\n",
       "15  Cocos (Keeling) Islands       Cook Islands        0.628571\n",
       "26            French Guiana   French Polynesia        0.620690\n",
       "43         Marshall Islands      Åland Islands        0.620690\n",
       "78          Western Pacific     Western Sahara        0.620690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "if countries_list:\n",
    "    print(countries_list)\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_Suicide_Rate'\n",
    "states_target_column_name = 'suicide_rate'\n",
    "mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'suicide_rate', us_states_df, st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='Suicide Rate per 100,000 Population (2019)',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_suicide_rate_Country_Equivalent_Suicice_Rate.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=states_target_column_name,\n",
    "                                                     string_column_name=equivalence_column_name,\n",
    "                                                     one_country_df=ssu.us_stats_df, cmap='winter')\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Prison Population Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (50, 4))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://worldpopulationreview.com/state-rankings/prison-population-by-state'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['State', 'Imprisonment Rate (per 100K)', 'Total Prison Population', '2022 Pop.']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>38</th>\n",
       "      <th>37</th>\n",
       "      <th>2</th>\n",
       "      <th>11</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imprisonment_rate_per_100k</th>\n",
       "      <td>241</td>\n",
       "      <td>242</td>\n",
       "      <td>633</td>\n",
       "      <td>428</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_prison_population</th>\n",
       "      <td>1782</td>\n",
       "      <td>8751</td>\n",
       "      <td>25338</td>\n",
       "      <td>2479</td>\n",
       "      <td>31584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_population_2022</th>\n",
       "      <td>738023</td>\n",
       "      <td>3612314</td>\n",
       "      <td>4000953</td>\n",
       "      <td>579495</td>\n",
       "      <td>4682633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                38           37        2        11         0 \n",
       "state_name                  Alaska  Connecticut  Oklahoma  Wyoming  Louisiana\n",
       "imprisonment_rate_per_100k     241          242       633      428        674\n",
       "total_prison_population       1782         8751     25338     2479      31584\n",
       "state_population_2022       738023      3612314   4000953   579495    4682633"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "print(us_states_df.columns.tolist())\n",
    "columns_list = ['imprisonment_rate_per_100k', 'total_prison_population', 'state_population_2022']\n",
    "us_states_df.columns = ['state_name'] + columns_list\n",
    "for cn in columns_list:\n",
    "    us_states_df[cn] = us_states_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='integer')\n",
    "mask_series = us_states_df.state_name.isnull()\n",
    "us_states_df = us_states_df[~mask_series]\n",
    "us_states_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (220, 5))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://worldpopulationreview.com/country-rankings/incarceration-rates-by-country'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Country', 'Incarceration Rate', 'Total Incarcerated', '% Male', '% Female']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>United States</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>El Salvador</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>Palau</td>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Panama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incarceration_rate</th>\n",
       "      <td>629.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_prison_population</th>\n",
       "      <td>2068800.0</td>\n",
       "      <td>76099.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>36663.0</td>\n",
       "      <td>57337.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>309282.0</td>\n",
       "      <td>18942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_prison_population_percent</th>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_prison_population_percent</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0        1             2  \\\n",
       "country_name                      United States   Rwanda  Turkmenistan   \n",
       "incarceration_rate                        629.0    580.0         576.0   \n",
       "total_prison_population               2068800.0  76099.0       35000.0   \n",
       "male_prison_population_percent               90       95            94   \n",
       "female_prison_population_percent             10        5             7   \n",
       "\n",
       "                                            3        4      5  \\\n",
       "country_name                      El Salvador     Cuba  Palau   \n",
       "incarceration_rate                      564.0    510.0  478.0   \n",
       "total_prison_population               36663.0  57337.0   86.0   \n",
       "male_prison_population_percent             93        0     95   \n",
       "female_prison_population_percent            7        0      5   \n",
       "\n",
       "                                                       6         7        8  \n",
       "country_name                      British Virgin Islands  Thailand   Panama  \n",
       "incarceration_rate                                 477.0     445.0    434.0  \n",
       "total_prison_population                            143.0  309282.0  18942.0  \n",
       "male_prison_population_percent                        96        89       95  \n",
       "female_prison_population_percent                       5        12        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[0].copy()\n",
    "print(countries_df.columns.tolist())\n",
    "columns_list = ['incarceration_rate',  'total_prison_population', 'male_prison_population_percent', 'female_prison_population_percent']\n",
    "countries_df.columns = ['country_name'] + columns_list\n",
    "for cn in columns_list:\n",
    "    countries_df[cn] = countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x).split('%')[0]))\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn], errors='coerce', downcast='integer')\n",
    "mask_series = countries_df.country_name.isnull()\n",
    "countries_df = countries_df[~mask_series]\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: str(x).split('*')[0].strip())\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antarctica', 'Bonaire, Sint Eustatius & Saba', 'Bouvet Island', 'British Indian Ocean Territory', 'Cape Verde', 'Christmas Island', 'Cocos (Keeling) Islands', \"Côte d'Ivoire\", 'Falkland Islands (Malvinas)', 'Federated States of Micronesia', 'French Southern Territories', 'Heard Island and McDonald Islands', 'Holy See', 'Ivory Coast', 'Micronesia', 'Montserrat', 'Niue', 'Norfolk Island', 'Palestine', 'Pitcairn', 'ROC', 'Réunion', 'Saint Helena, Ascension & Tristan da Cunha', 'South Georgia and the South Sandwich Islands', 'St. Barthélemy', 'St. Martin', 'St. Pierre & Miquelon', 'Svalbard and Jan Mayen', 'Tokelau', 'Turks & Caicos Islands', 'UK', 'United States Minor Outlying Islands', 'Wallis & Futuna', 'Western Sahara', 'Åland Islands']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "if countries_list:\n",
    "    print(countries_list)\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_Prison_Population'\n",
    "states_target_column_name = 'total_prison_population'\n",
    "mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'total_prison_population', us_states_df, st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='Total Incarcerated (2020)',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_total_prison_population_Country_Equivalent_Prison_Population.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=states_target_column_name,\n",
    "                                                     string_column_name=equivalence_column_name,\n",
    "                                                     one_country_df=ssu.us_stats_df)\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Intentional Homicide Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (54, 12)), (1, (11, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_intentional_homicide_rate'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>44</th>\n",
       "      <th>29</th>\n",
       "      <th>37</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>California</td>\n",
       "      <td>Washington</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_victums_2020</th>\n",
       "      <td>308.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2020</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2019</th>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2018</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2017</th>\n",
       "      <td>3.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2016</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2015</th>\n",
       "      <td>4.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2014</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2013</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2012</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder_rates_per_100k_people_2011</th>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          30       44          29          37  \\\n",
       "state_name                         Wisconsin  Wyoming  California  Washington   \n",
       "murder_victums_2020                    308.0     18.0      2203.0       301.0   \n",
       "murder_rates_per_100k_people_2020        5.3      3.1         5.6         3.9   \n",
       "murder_rates_per_100k_people_2019        3.2      2.2         4.3         2.7   \n",
       "murder_rates_per_100k_people_2018        3.0      2.4         4.4         3.1   \n",
       "murder_rates_per_100k_people_2017        3.3      2.4         4.6         3.0   \n",
       "murder_rates_per_100k_people_2016        4.0      3.4         4.9         2.9   \n",
       "murder_rates_per_100k_people_2015        4.2      2.7         4.8         2.5   \n",
       "murder_rates_per_100k_people_2014        2.8      2.7         4.4         2.3   \n",
       "murder_rates_per_100k_people_2013        2.8      2.9         4.6         3.1   \n",
       "murder_rates_per_100k_people_2012        3.0      2.4         5.0         2.4   \n",
       "murder_rates_per_100k_people_2011        2.4      3.2         4.8         2.3   \n",
       "\n",
       "                                              52  \n",
       "state_name                         New Hampshire  \n",
       "murder_victums_2020                         12.0  \n",
       "murder_rates_per_100k_people_2020            0.9  \n",
       "murder_rates_per_100k_people_2019            2.4  \n",
       "murder_rates_per_100k_people_2018            1.6  \n",
       "murder_rates_per_100k_people_2017            1.0  \n",
       "murder_rates_per_100k_people_2016            1.4  \n",
       "murder_rates_per_100k_people_2015            1.1  \n",
       "murder_rates_per_100k_people_2014            1.2  \n",
       "murder_rates_per_100k_people_2013            1.7  \n",
       "murder_rates_per_100k_people_2012            1.1  \n",
       "murder_rates_per_100k_people_2011            1.3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "# print(us_states_df.columns.tolist())\n",
    "columns_list = ['murder_victums_2020'] + [f'murder_rates_per_100k_people_{i}' for i in range(2020, 2010, -1)]\n",
    "us_states_df.columns = ['state_name'] + columns_list\n",
    "for cn in columns_list:\n",
    "    us_states_df[cn] = us_states_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='float')\n",
    "mask_series = us_states_df.state_name.isnull()\n",
    "us_states_df = us_states_df[~mask_series]\n",
    "us_states_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (us_states_df.state_name == 'District of Columbia')\n",
    "us_states_df = us_states_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (196, 7)), (2, (49, 2)), (3, (16, 2)), (0, (6, 3)), (4, (6, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Armenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_name</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subregion_name</th>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Middle Africa</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>South America</td>\n",
       "      <td>Western Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homicide_rate</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>28.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_count</th>\n",
       "      <td>2474.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_source_year</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_source</th>\n",
       "      <td>NSO</td>\n",
       "      <td>NSO</td>\n",
       "      <td>CTS</td>\n",
       "      <td>CTS</td>\n",
       "      <td>NSO</td>\n",
       "      <td>SDG</td>\n",
       "      <td>OAS</td>\n",
       "      <td>MoS</td>\n",
       "      <td>CTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              1                2                3  \\\n",
       "country_name        Afghanistan          Albania          Algeria   \n",
       "region_name                Asia           Europe           Africa   \n",
       "subregion_name    Southern Asia  Southern Europe  Northern Africa   \n",
       "homicide_rate               6.7              2.1              1.3   \n",
       "body_count               2474.0             61.0            580.0   \n",
       "data_source_year         2018.0           2020.0           2020.0   \n",
       "data_source                 NSO              NSO              CTS   \n",
       "\n",
       "                                4              5          6  \\\n",
       "country_name              Andorra         Angola   Anguilla   \n",
       "region_name                Europe         Africa   Americas   \n",
       "subregion_name    Southern Europe  Middle Africa  Caribbean   \n",
       "homicide_rate                 2.6            4.8       28.3   \n",
       "body_count                    2.0         1217.0        4.0   \n",
       "data_source_year           2020.0         2012.0     2014.0   \n",
       "data_source                   CTS            NSO        SDG   \n",
       "\n",
       "                                    7              8             9  \n",
       "country_name      Antigua and Barbuda      Argentina       Armenia  \n",
       "region_name                  Americas       Americas          Asia  \n",
       "subregion_name              Caribbean  South America  Western Asia  \n",
       "homicide_rate                    11.1            5.3           1.8  \n",
       "body_count                       10.0         2362.0          52.0  \n",
       "data_source_year               2012.0         2018.0        2020.0  \n",
       "data_source                       OAS            MoS           CTS  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[1].copy()\n",
    "# print(countries_df.columns.tolist())\n",
    "countries_df.columns = ['country_name', 'region_name',  'subregion_name', 'homicide_rate',\n",
    "                        'body_count', 'data_source_year', 'data_source']\n",
    "for cn in ['homicide_rate', 'body_count', 'data_source_year']:\n",
    "    countries_df[cn] = countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x).split('[')[0]))\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn], errors='coerce', downcast='integer')\n",
    "mask_series = countries_df.country_name.isnull()\n",
    "countries_df = countries_df[~mask_series]\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: str(x).split('*')[0].strip())\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Channel Islands</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>North Korea</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Togo</td>\n",
       "      <td>Tonga</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 first_item               second_item  max_similarity\n",
       "11             Cook Islands            Norfolk Island        0.769231\n",
       "7           Channel Islands             Faroe Islands        0.714286\n",
       "28                 Guernsey                    Jersey        0.714286\n",
       "57          Solomon Islands             Åland Islands        0.714286\n",
       "47         Northern Ireland  Northern Mariana Islands        0.700000\n",
       "3             Bouvet Island             Faroe Islands        0.692308\n",
       "20            Faroe Islands             Åland Islands        0.692308\n",
       "46              North Korea          Northern Ireland        0.666667\n",
       "63                     Togo                     Tonga        0.666667\n",
       "9   Cocos (Keeling) Islands              Cook Islands        0.628571\n",
       "40         Marshall Islands             Åland Islands        0.620690\n",
       "45           Norfolk Island           Solomon Islands        0.620690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\us_stats_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\column_description_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_Intentional_Homicide_Rate'\n",
    "states_target_column_name = 'murder_rates_per_100k_people_2020'\n",
    "mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'homicide_rate', us_states_df, st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='Intentional Homicides per 100,000 Population (2020)',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_murder_rates_per_100k_people_2020_Country_Equivalent_Intentional_Homicide_Rate.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=states_target_column_name,\n",
    "                                                     string_column_name=equivalence_column_name,\n",
    "                                                     one_country_df=ssu.us_stats_df, cmap='summer')\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Car Fatality Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Aug 17, 2022 6:14:27 PM org.apache.pdfbox.pdfparser.COSParser parseXref\n",
      "WARNING: /XRefStm offset 3129 is incorrect, corrected to 3278\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, (56, 9)), (7, (56, 6)), (6, (55, 3)), (8, (55, 7)), (9, (55, 7)), (10, (55, 5)), (4, (54, 9)), (5, (54, 7)), (2, (46, 3)), (0, (26, 19)), (11, (21, 2)), (1, (5, 4))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# url = 'https://worldpopulationreview.com/state-rankings/fatal-car-accidents-by-state'\n",
    "url = 'https://crashstats.nhtsa.dot.gov/Api/Public/Publication/812581'\n",
    "file_name = '2016_State_Traffic_Data_CrashStats_NHTSA.pdf'\n",
    "tables_list = ssu.get_page_tables(url, pdf_file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic Fatalities</th>\n",
       "      <td>1038.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>3623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population (thousands)</th>\n",
       "      <td>4863.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>6931.0</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>39250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Licensed Drivers (thousands)</th>\n",
       "      <td>3943.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>5082.0</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>26199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Registered Vehicles (thousands)</th>\n",
       "      <td>5468.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>5787.0</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>30221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vehicle Miles Traveled (millions)</th>\n",
       "      <td>69227.0</td>\n",
       "      <td>5259.0</td>\n",
       "      <td>65786.0</td>\n",
       "      <td>35755.0</td>\n",
       "      <td>340115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatality_rates_per_100k_population</th>\n",
       "      <td>21.34</td>\n",
       "      <td>11.32</td>\n",
       "      <td>13.88</td>\n",
       "      <td>18.24</td>\n",
       "      <td>9.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fatality Rates per 100 Million Vehicle Miles Traveled</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fatality Rates per 100,000 Licensed Drivers</th>\n",
       "      <td>26.32</td>\n",
       "      <td>15.71</td>\n",
       "      <td>18.93</td>\n",
       "      <td>22.790001</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fatality Rates per 100,000 Registered Vehicles</th>\n",
       "      <td>18.98</td>\n",
       "      <td>10.57</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>19.41</td>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          3       4  \\\n",
       "state_name                                          Alabama  Alaska   \n",
       "Traffic Fatalities                                   1038.0    84.0   \n",
       "Population (thousands)                               4863.0   742.0   \n",
       "Licensed Drivers (thousands)                         3943.0   535.0   \n",
       "Registered Vehicles (thousands)                      5468.0   795.0   \n",
       "Vehicle Miles Traveled (millions)                   69227.0  5259.0   \n",
       "fatality_rates_per_100k_population                    21.34   11.32   \n",
       "Fatality Rates per 100 Million Vehicle Miles Tr...      1.5     1.6   \n",
       "Fatality Rates per 100,000 Licensed Drivers           26.32   15.71   \n",
       "Fatality Rates per 100,000 Registered Vehicles        18.98   10.57   \n",
       "\n",
       "                                                            5          6  \\\n",
       "state_name                                            Arizona   Arkansas   \n",
       "Traffic Fatalities                                      962.0      545.0   \n",
       "Population (thousands)                                 6931.0     2988.0   \n",
       "Licensed Drivers (thousands)                           5082.0     2391.0   \n",
       "Registered Vehicles (thousands)                        5787.0     2808.0   \n",
       "Vehicle Miles Traveled (millions)                     65786.0    35755.0   \n",
       "fatality_rates_per_100k_population                      13.88      18.24   \n",
       "Fatality Rates per 100 Million Vehicle Miles Tr...       1.46       1.52   \n",
       "Fatality Rates per 100,000 Licensed Drivers             18.93  22.790001   \n",
       "Fatality Rates per 100,000 Registered Vehicles      16.620001      19.41   \n",
       "\n",
       "                                                             7  \n",
       "state_name                                          California  \n",
       "Traffic Fatalities                                      3623.0  \n",
       "Population (thousands)                                 39250.0  \n",
       "Licensed Drivers (thousands)                           26199.0  \n",
       "Registered Vehicles (thousands)                        30221.0  \n",
       "Vehicle Miles Traveled (millions)                     340115.0  \n",
       "fatality_rates_per_100k_population                        9.23  \n",
       "Fatality Rates per 100 Million Vehicle Miles Tr...        1.07  \n",
       "Fatality Rates per 100,000 Licensed Drivers              13.83  \n",
       "Fatality Rates per 100,000 Registered Vehicles           11.99  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[3].copy()\n",
    "# columns_list = []\n",
    "# for t1, t2, t3, t4 in zip(us_states_df.columns.tolist(), us_states_df.iloc[0].T.tolist(), us_states_df.iloc[1].T.tolist(),\n",
    "#                           us_states_df.iloc[2].T.tolist()):\n",
    "#     column_names_list = []\n",
    "#     if not t1.startswith('Unnamed'):\n",
    "#         column_names_list.append(t1.strip().lower().replace(' ', '_').replace(',000', 'k'))\n",
    "#     for t in [t2, t3, t4]:\n",
    "#         if str(t) != 'nan':\n",
    "#             column_names_list.append(t.strip().lower().replace(' ', '_').replace(',000', 'k'))\n",
    "#     columns_list.append('_'.join(column_names_list))\n",
    "# print(columns_list)\n",
    "columns_list = ['traffic_fatalities', 'population_in_thousands', 'licensed_drivers_in_thousands',\n",
    "                'registered_vehicles_in_thousands', 'vehicle_miles_traveled_in_millions', 'fatality_rates_per_100k_population']\n",
    "us_states_df.columns = ['state_name'] + columns_list + ['fixme', 'fatality_rates_per_100_million_vehicle_miles_traveled']\n",
    "us_states_df = us_states_df.iloc[3:]\n",
    "fixme_columns_list = ['fatality_rates_per_100k_licensed_drivers', 'fatality_rates_per_100k_registered_vehicles']\n",
    "for i in range(2):\n",
    "    us_states_df[fixme_columns_list[i]] = us_states_df.fixme.map(lambda x: re.sub(r'[^0-9\\.]+', '', x.split(' ')[i]))\n",
    "for cn in fixme_columns_list:\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='float')\n",
    "columns_list += ['fatality_rates_per_100_million_vehicle_miles_traveled']\n",
    "for cn in columns_list:\n",
    "    us_states_df[cn] = us_states_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x)))\n",
    "    us_states_df[cn] = pd.to_numeric(us_states_df[cn], errors='coerce', downcast='float')\n",
    "columns_list = ['state_name'] + columns_list + fixme_columns_list\n",
    "us_states_df[columns_list].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_item, second_item, max_similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (189, 7)), (2, (4, 2)), (0, (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_traffic-related_death_rate'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>Global</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Eastern Mediterranean</td>\n",
       "      <td>Western Pacific</td>\n",
       "      <td>South-East Asia</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent_name</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100k_inhabitants</th>\n",
       "      <td>18.200001</td>\n",
       "      <td>26.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100k_motor_vehicles</th>\n",
       "      <td>NaN</td>\n",
       "      <td>574.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>722.400024</td>\n",
       "      <td>107.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100B_vehicle_kms</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_total</th>\n",
       "      <td>1350000.0</td>\n",
       "      <td>246719.0</td>\n",
       "      <td>122730.0</td>\n",
       "      <td>328591.0</td>\n",
       "      <td>316080.0</td>\n",
       "      <td>153789.0</td>\n",
       "      <td>85629.0</td>\n",
       "      <td>4734.0</td>\n",
       "      <td>478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_source_year</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0         1  \\\n",
       "country_name                            Global    Africa   \n",
       "continent_name                             NaN       NaN   \n",
       "road_deaths_per_100k_inhabitants     18.200001      26.6   \n",
       "road_deaths_per_100k_motor_vehicles        NaN     574.0   \n",
       "road_deaths_per_100B_vehicle_kms           NaN       NaN   \n",
       "road_deaths_total                    1350000.0  246719.0   \n",
       "data_source_year                        2016.0    2016.0   \n",
       "\n",
       "                                                         2                3  \\\n",
       "country_name                         Eastern Mediterranean  Western Pacific   \n",
       "continent_name                                         NaN              NaN   \n",
       "road_deaths_per_100k_inhabitants                      18.0             16.9   \n",
       "road_deaths_per_100k_motor_vehicles                  139.0             69.0   \n",
       "road_deaths_per_100B_vehicle_kms                       NaN              NaN   \n",
       "road_deaths_total                                 122730.0         328591.0   \n",
       "data_source_year                                    2016.0           2016.0   \n",
       "\n",
       "                                                   4         5        6  \\\n",
       "country_name                         South-East Asia  Americas   Europe   \n",
       "continent_name                                   NaN       NaN      NaN   \n",
       "road_deaths_per_100k_inhabitants           20.700001      15.6      9.3   \n",
       "road_deaths_per_100k_motor_vehicles            101.0      33.0     19.0   \n",
       "road_deaths_per_100B_vehicle_kms                 NaN       NaN      NaN   \n",
       "road_deaths_total                           316080.0  153789.0  85629.0   \n",
       "data_source_year                              2016.0    2016.0   2016.0   \n",
       "\n",
       "                                               7           8  \n",
       "country_name                         Afghanistan     Albania  \n",
       "continent_name                              Asia      Europe  \n",
       "road_deaths_per_100k_inhabitants            15.5        15.1  \n",
       "road_deaths_per_100k_motor_vehicles   722.400024  107.199997  \n",
       "road_deaths_per_100B_vehicle_kms             NaN         NaN  \n",
       "road_deaths_total                         4734.0       478.0  \n",
       "data_source_year                          2013.0      2016.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[1].copy()\n",
    "# print(countries_df.columns.tolist())\n",
    "countries_df.columns = ['country_name', 'continent_name',  'road_deaths_per_100k_inhabitants',\n",
    "                        'road_deaths_per_100k_motor_vehicles', 'road_deaths_per_100B_vehicle_kms', 'road_deaths_total',\n",
    "                        'data_source_year']\n",
    "for cn in ['road_deaths_per_100k_inhabitants', 'road_deaths_per_100k_motor_vehicles', 'road_deaths_per_100B_vehicle_kms',\n",
    "           'road_deaths_total', 'data_source_year']:\n",
    "    countries_df[cn] = countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x).split('[')[0]))\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn], errors='coerce', downcast='float')\n",
    "countries_df.head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <td>Iceland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent_name</th>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100k_inhabitants</th>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100k_motor_vehicles</th>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100B_vehicle_kms</th>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_total</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_source_year</th>\n",
       "      <td>5.20162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          76\n",
       "country_name                         Iceland\n",
       "continent_name                        Europe\n",
       "road_deaths_per_100k_inhabitants         3.8\n",
       "road_deaths_per_100k_motor_vehicles      7.6\n",
       "road_deaths_per_100B_vehicle_kms         4.9\n",
       "road_deaths_total                        8.0\n",
       "data_source_year                     5.20162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask_series = (countries_df.country_name == 'Iceland')\n",
    "countries_df[mask_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Greenland</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Americas</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>Americas</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Western Pacific</td>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_item        second_item  max_similarity\n",
       "12  British Virgin Islands  US Virgin Islands        0.769231\n",
       "35               Greenland            Grenada        0.750000\n",
       "16          Cayman Islands      Åland Islands        0.740741\n",
       "65            Sint Maarten         St. Martin        0.727273\n",
       "0                   Africa           Americas        0.714286\n",
       "39                Guernsey             Jersey        0.714286\n",
       "10           Bouvet Island      Faroe Islands        0.692308\n",
       "29           Faroe Islands      Åland Islands        0.692308\n",
       "1           American Samoa           Americas        0.636364\n",
       "30           French Guiana   French Polynesia        0.620690\n",
       "87         Western Pacific     Western Sahara        0.620690"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100k_inhabitants</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100k_motor_vehicles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_per_100B_vehicle_kms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road_deaths_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_source_year</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [country_name, continent_name, road_deaths_per_100k_inhabitants, road_deaths_per_100k_motor_vehicles, road_deaths_per_100B_vehicle_kms, road_deaths_total, data_source_year]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "countries_df[mask_series].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\us_stats_df.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\column_description_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "equivalence_column_name = 'Country_Equivalent_Road_Deaths_per_100k_Inhabitants'\n",
    "states_target_column_name = 'fatality_rates_per_100k_population'\n",
    "mask_series = countries_df.country_name.isin(all_countries_df.country_name)\n",
    "ssu.prepare_for_choroplething(countries_df[mask_series], 'road_deaths_per_100k_inhabitants', us_states_df, st_col_name=states_target_column_name,\n",
    "                              st_col_explanation='Road Deaths per 100,000 Population',\n",
    "                              equivalence_column_name=equivalence_column_name, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_fatality_rates_per_100k_population_Country_Equivalent_Road_Deaths_per_100k_Inhabitants.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = ChoroplethUtilities(iso_3166_2_code='us', one_country_df=ssu.us_stats_df, all_countries_df=all_countries_df)\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=states_target_column_name,\n",
    "                                                     string_column_name=equivalence_column_name,\n",
    "                                                     one_country_df=ssu.us_stats_df)\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Physicians per Capita Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (52, 4))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.beckershospitalreview.com/workforce/this-state-has-the-most-physicians-per-capita.html'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_active_physicians</th>\n",
       "      <th>physicians_per_10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>731545</td>\n",
       "      <td>2101</td>\n",
       "      <td>287.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>705749</td>\n",
       "      <td>6147</td>\n",
       "      <td>87.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7278717</td>\n",
       "      <td>18343</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6892503</td>\n",
       "      <td>32116</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>11689100</td>\n",
       "      <td>35333</td>\n",
       "      <td>302.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              state_name total_population total_active_physicians  \\\n",
       "22                Alaska           731545                    2101   \n",
       "1   District of Columbia           705749                    6147   \n",
       "32               Arizona          7278717                   18343   \n",
       "2          Massachusetts          6892503                   32116   \n",
       "15                  Ohio         11689100                   35333   \n",
       "\n",
       "    physicians_per_10k  \n",
       "22               287.2  \n",
       "1                 87.1  \n",
       "32                25.2  \n",
       "2                 46.6  \n",
       "15               302.3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "states_target_column_name = 'physicians_per_10k'\n",
    "us_states_df.columns = ['state_name', 'total_population', 'total_active_physicians', states_target_column_name]\n",
    "us_states_df = us_states_df.iloc[1:]\n",
    "us_states_df[states_target_column_name] = pd.to_numeric(us_states_df[states_target_column_name].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x))),\n",
    "                                                        errors='coerce', downcast='float')\n",
    "us_states_df[states_target_column_name] = us_states_df[states_target_column_name].map(lambda x: x/10)\n",
    "us_states_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_active_physicians</th>\n",
       "      <th>physicians_per_10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6892503</td>\n",
       "      <td>32116</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>19453561</td>\n",
       "      <td>75749</td>\n",
       "      <td>389.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state_name total_population total_active_physicians  physicians_per_10k\n",
       "2  Massachusetts          6892503                   32116                46.6\n",
       "4       New York         19453561                   75749               389.4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Why does MA only have 46.6 physicians per 10K whilst NY has 389.4?\n",
    "mask_series = us_states_df.state_name.isin(['Massachusetts', 'New York'])\n",
    "us_states_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_item, second_item, max_similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (188, 5)), (0, (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tables_list = ssu.get_page_tables('https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_number_of_physicians', driver=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>total_population</th>\n",
       "      <th>physicians_per_10k_2009</th>\n",
       "      <th>physicians_per_10k_2013</th>\n",
       "      <th>physicians_per_10k_latest</th>\n",
       "      <th>physicians_per_10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>19612</td>\n",
       "      <td>100.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>31175</td>\n",
       "      <td>380.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>32388</td>\n",
       "      <td>380.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>3626</td>\n",
       "      <td>110.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>40857</td>\n",
       "      <td>120.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name  total_population  physicians_per_10k_2009  \\\n",
       "0    Australia             19612                    100.0   \n",
       "1      Austria             31175                    380.0   \n",
       "2   Azerbaijan             32388                    380.0   \n",
       "3      Albania              3626                    110.0   \n",
       "4      Algeria             40857                    120.0   \n",
       "\n",
       "   physicians_per_10k_2013  physicians_per_10k_latest  physicians_per_10k  \n",
       "0                    327.0                        NaN               327.0  \n",
       "1                    483.0                        NaN               483.0  \n",
       "2                    340.0                        NaN               340.0  \n",
       "3                    115.0                        NaN               115.0  \n",
       "4                    121.0                      172.0               172.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[1].copy()\n",
    "# print(countries_df.columns.tolist())\n",
    "countries_target_column_name = 'physicians_per_10k'\n",
    "LATEST_COLUMN_NAME = countries_target_column_name + '_latest'\n",
    "EARLIER_COLUMN_NAME = countries_target_column_name + '_2013'\n",
    "EARLIEST_COLUMN_NAME = countries_target_column_name + '_2009'\n",
    "countries_df.columns = ['country_name', 'total_population', EARLIEST_COLUMN_NAME, EARLIER_COLUMN_NAME, LATEST_COLUMN_NAME]\n",
    "for cn in [EARLIEST_COLUMN_NAME, EARLIER_COLUMN_NAME, LATEST_COLUMN_NAME]:\n",
    "    countries_df[cn] = pd.to_numeric(countries_df[cn].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x))), errors='coerce', downcast='float')\n",
    "def f(row_series):\n",
    "    latest = row_series[LATEST_COLUMN_NAME]\n",
    "    earlier = row_series[EARLIER_COLUMN_NAME]\n",
    "    earliest = row_series[EARLIEST_COLUMN_NAME]\n",
    "    for cv in [latest, earlier, earliest]:\n",
    "        if str(cv) != 'nan':\n",
    "\n",
    "            return cv\n",
    "countries_df[countries_target_column_name] = countries_df.apply(f, axis='columns')\n",
    "countries_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>total_population</th>\n",
       "      <th>physicians_per_10k_2009</th>\n",
       "      <th>physicians_per_10k_2013</th>\n",
       "      <th>physicians_per_10k_latest</th>\n",
       "      <th>physicians_per_10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>France</td>\n",
       "      <td>227683</td>\n",
       "      <td>370.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country_name  total_population  physicians_per_10k_2009  \\\n",
       "170       France            227683                    370.0   \n",
       "\n",
       "     physicians_per_10k_2013  physicians_per_10k_latest  physicians_per_10k  \n",
       "170                    319.0                      327.0               327.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# France has 327.0 physicians per 10K whilst NY has 389.4?\n",
    "mask_series = countries_df.country_name.isin(['France'])\n",
    "countries_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Greenland</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_item        second_item  max_similarity\n",
       "12  British Virgin Islands  US Virgin Islands        0.769231\n",
       "31               Greenland            Grenada        0.750000\n",
       "16          Cayman Islands      Åland Islands        0.740741\n",
       "59            Sint Maarten         St. Martin        0.727273\n",
       "35                Guernsey             Jersey        0.714286\n",
       "10           Bouvet Island      Faroe Islands        0.692308\n",
       "25           Faroe Islands      Åland Islands        0.692308\n",
       "27           French Guiana   French Polynesia        0.620690"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Create Equivalence Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_to_country_equivalent_dict, country_to_state_equivalent_dict = ssu.get_country_state_equivalents(\n",
    "    countries_df, 'country_name', countries_target_column_name,\n",
    "    us_states_df, 'state_name', states_target_column_name,\n",
    "    cn_col_explanation=None, st_col_explanation=None,\n",
    "    countries_set=None, states_set=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\us_stats_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "string_column_name = 'Country_Equivalent_Physicians_per_Capita'\n",
    "us_stats_df[string_column_name] = us_stats_df.index.map(lambda x: state_to_country_equivalent_dict.get(x, x))\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\column_description_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "states_dict = us_states_df.set_index('state_name')[states_target_column_name].to_dict()\n",
    "states_min = us_states_df[states_target_column_name].min()\n",
    "us_stats_df[states_target_column_name] = us_stats_df.index.map(lambda x: states_dict.get(x, states_min))\n",
    "column_description_dict[states_target_column_name] = 'Physicians per Capita by State (latest)'\n",
    "s.store_objects(column_description_dict=column_description_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_physicians_per_10k_Country_Equivalent_Physicians_per_Capita.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=states_target_column_name,\n",
    "                                                     string_column_name=string_column_name,\n",
    "                                                     one_country_df=us_stats_df)\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Health Care Costs Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (50, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://worldpopulationreview.com/state-rankings/health-care-costs-by-state'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>spending_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>7651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>7214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>9851.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state_name  spending_per_capita\n",
       "30        Indiana               7651.0\n",
       "40  New Hampshire               7214.0\n",
       "34        Arizona               7549.0\n",
       "49        Wyoming                  NaN\n",
       "4        New York               9851.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "states_target_column_name = 'spending_per_capita'\n",
    "us_states_df.columns = ['state_name', states_target_column_name]\n",
    "us_states_df[states_target_column_name] = pd.to_numeric(us_states_df[states_target_column_name].map(lambda x: re.sub(r'[^0-9\\.]+', '', str(x))),\n",
    "                                                        errors='coerce', downcast='integer')\n",
    "us_states_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_item, second_item, max_similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the FireFox driver\n",
      "No tables found\n",
      "[]\n",
      "[(0, (248, 3))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = ssu.get_driver()\n",
    "tables_list = ssu.get_page_tables('https://data.worldbank.org/indicator/SH.XPD.CHEX.PC.CD', driver=driver)\n",
    "driver.close()\n",
    "if not tables_list:\n",
    "    tables_list = ssu.get_page_tables('../data/html/world_bank_healthcare_apending_per_capita_by_country.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>study_year</th>\n",
       "      <th>spending_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Micronesia, Fed. Sts.</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>5325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>104945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>27491.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country_name  study_year  spending_per_capita\n",
       "128  Micronesia, Fed. Sts.      2019.0               4152.0\n",
       "138                  Nepal      2019.0               5325.0\n",
       "137                  Nauru      2019.0             104945.0\n",
       "185                  Sudan      2019.0               4693.0\n",
       "1                  Albania      2018.0              27491.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[0].copy()\n",
    "countries_target_column_name = 'spending_per_capita'\n",
    "countries_df.columns = ['country_name', 'study_year', countries_target_column_name]\n",
    "# print(countries_df.columns.tolist())\n",
    "countries_df[countries_target_column_name] = pd.to_numeric(countries_df[countries_target_column_name].map(lambda x: re.sub(r'[^0-9\\.]+', '',\n",
    "                                                                                                                           str(x))),\n",
    "                                                        errors='coerce', downcast='float')\n",
    "countries_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Equivalence Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_to_country_equivalent_dict, country_to_state_equivalent_dict = ssu.get_country_state_equivalents(\n",
    "    countries_df, 'country_name', countries_target_column_name,\n",
    "    us_states_df, 'state_name', states_target_column_name,\n",
    "    cn_col_explanation=None, st_col_explanation=None,\n",
    "    countries_set=None, states_set=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "string_column_name = 'Country_Equivalent_Health_Care_Costs'\n",
    "us_stats_df[string_column_name] = us_stats_df.index.map(lambda x: state_to_country_equivalent_dict.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\column_description_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "states_dict = us_states_df.set_index('state_name')[states_target_column_name].to_dict()\n",
    "states_min = us_states_df[states_target_column_name].min()\n",
    "us_stats_df[states_target_column_name] = us_stats_df.index.map(lambda x: states_dict.get(x, states_min))\n",
    "column_description_dict[states_target_column_name] = 'Health Care Costs by State (2022)'\n",
    "s.store_objects(column_description_dict=column_description_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_spending_per_capita_Country_Equivalent_Health_Care_Costs.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c.create_label_line_file()\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=states_target_column_name,\n",
    "                                                     string_column_name=string_column_name,\n",
    "                                                     one_country_df=us_stats_df)\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Life Expectency Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (50, 7))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://worldpopulationreview.com/state-rankings/life-expectancy-by-state'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>life_expectancy_black</th>\n",
       "      <th>life_expectancy_latino</th>\n",
       "      <th>life_expectancy_asian</th>\n",
       "      <th>life_expectancy_native_american</th>\n",
       "      <th>life_expectancy_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>77.80</td>\n",
       "      <td>74.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.90</td>\n",
       "      <td>76.60</td>\n",
       "      <td>78.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>76.20</td>\n",
       "      <td>74.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>79.90</td>\n",
       "      <td>78.80</td>\n",
       "      <td>87.10</td>\n",
       "      <td>89.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>74.90</td>\n",
       "      <td>72.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>80.40</td>\n",
       "      <td>75.50</td>\n",
       "      <td>84.70</td>\n",
       "      <td>89.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_name      life_expectancy  life_expectancy_black  \\\n",
       "33  North Carolina                77.80                  74.70   \n",
       "41  South Carolina                76.20                  74.00   \n",
       "8    Massachusetts                79.90                  78.80   \n",
       "47         Alabama                74.90                  72.90   \n",
       "5       New Jersey                80.40                  75.50   \n",
       "\n",
       "    life_expectancy_latino  life_expectancy_asian  \\\n",
       "33                     NaN                  88.90   \n",
       "41                     NaN                    NaN   \n",
       "8                    87.10                  89.10   \n",
       "47                     NaN                  76.00   \n",
       "5                    84.70                  89.40   \n",
       "\n",
       "    life_expectancy_native_american  life_expectancy_white  \n",
       "33                            76.60                  78.30  \n",
       "41                              NaN                  77.80  \n",
       "8                               NaN                  80.40  \n",
       "47                              NaN                  76.00  \n",
       "5                               NaN                  80.30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "life_expectancy_us_states_df = tables_list[0].copy()\n",
    "life_expectancy_us_states_df.columns = ['state_name', 'life_expectancy', 'life_expectancy_black', 'life_expectancy_latino',\n",
    "                                        'life_expectancy_asian', 'life_expectancy_native_american', 'life_expectancy_white']\n",
    "life_expectancy_us_states_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the FireFox driver\n",
      "[(0, (237, 4))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://worldpopulationreview.com/countries/life-expectancy'\n",
    "driver = ssu.get_driver()\n",
    "tables_list = ssu.get_page_tables(url, driver=driver)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>life_expectancy_males</th>\n",
       "      <th>life_expectancy_females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>79.72</td>\n",
       "      <td>75.58</td>\n",
       "      <td>83.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Senegal</td>\n",
       "      <td>67.91</td>\n",
       "      <td>65.47</td>\n",
       "      <td>70.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Seychelles</td>\n",
       "      <td>71.74</td>\n",
       "      <td>68.24</td>\n",
       "      <td>76.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Bahamas</td>\n",
       "      <td>74.36</td>\n",
       "      <td>70.76</td>\n",
       "      <td>77.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>68.62</td>\n",
       "      <td>64.22</td>\n",
       "      <td>73.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country_name      life_expectancy  life_expectancy_males  \\\n",
       "177  Puerto Rico                79.72                  75.58   \n",
       "55       Senegal                67.91                  65.47   \n",
       "13    Seychelles                71.74                  68.24   \n",
       "162      Bahamas                74.36                  70.76   \n",
       "114      Moldova                68.62                  64.22   \n",
       "\n",
       "     life_expectancy_females  \n",
       "177                    83.90  \n",
       "55                     70.20  \n",
       "13                     76.04  \n",
       "162                    77.84  \n",
       "114                    73.32  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "life_expectancy_countries_df = tables_list[0].copy()\n",
    "life_expectancy_countries_df.columns = ['country_name', 'life_expectancy', 'life_expectancy_males', 'life_expectancy_females']\n",
    "life_expectancy_countries_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>life_expectancy_males</th>\n",
       "      <th>life_expectancy_females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country_name, life_expectancy, life_expectancy_males, life_expectancy_females]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask_series = life_expectancy_countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "life_expectancy_countries_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Falkland Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          first_item    second_item       max_similarity\n",
       "13  Falkland Islands  Åland Islands                 0.83"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "life_expectancy_countries_df.country_name = life_expectancy_countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(life_expectancy_countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_item, second_item, max_similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "states_list = sorted(set(life_expectancy_us_states_df.state_name).symmetric_difference(set(us_stats_df.index)))\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_to_country_equivalent_dict, country_to_state_equivalent_dict = ssu.get_country_state_equivalents(life_expectancy_countries_df,\n",
    "                                                                                                       'country_name',\n",
    "                                                                                                       'life_expectancy',\n",
    "                                                                                                       life_expectancy_us_states_df,\n",
    "                                                                                                       'state_name',\n",
    "                                                                                                       'life_expectancy',\n",
    "                                                                                                       verbose=False)\n",
    "state_to_country_equivalent_dict, country_to_state_equivalent_dict = ssu.get_country_state_equivalents(\n",
    "    countries_df, 'country_name', countries_target_column_name,\n",
    "    us_states_df, 'state_name', states_target_column_name,\n",
    "    cn_col_explanation=None, st_col_explanation=None,\n",
    "    countries_set=None, states_set=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df['Country_Equivalent_Life_Expectancy'] = us_stats_df.index.map(lambda x: state_to_country_equivalent_dict.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\column_description_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "life_expectancy_dict = life_expectancy_us_states_df.set_index('state_name').life_expectancy.to_dict()\n",
    "min_life = life_expectancy_us_states_df.life_expectancy.min()\n",
    "us_stats_df['life_expectancy'] = us_stats_df.index.map(lambda x: life_expectancy_dict.get(x, min_life))\n",
    "column_description_dict['life_expectancy'] = 'Overall average life expectency (2020)'\n",
    "s.store_objects(column_description_dict=column_description_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_life_expectancy_Country_Equivalent_Life_Expectancy.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c.create_label_line_file()\n",
    "numeric_column_name = 'life_expectancy'\n",
    "string_column_name = 'Country_Equivalent_Life_Expectancy'\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=numeric_column_name,\n",
    "                                                     string_column_name=string_column_name,\n",
    "                                                     one_country_df=us_stats_df)\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Obesity Equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare US States dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (56, 6)), (1, (24, 2)), (10, (11, 2)), (12, (11, 2)), (4, (9, 2)), (5, (8, 2)), (6, (6, 2)), (8, (4, 2)), (2, (3, 2)), (9, (3, 2)), (11, (2, 2)), (3, (1, 2)), (7, (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Obesity_in_the_United_States'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>obesity_rank</th>\n",
       "      <th>adults_obesity_rate_2005</th>\n",
       "      <th>adults_obesity_rate_2020</th>\n",
       "      <th>adults_overweight_rate_2005</th>\n",
       "      <th>children_and_adolescents_obesity_rate_2005</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>34.3</td>\n",
       "      <td>66.8</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>36.3</td>\n",
       "      <td>65.4</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>32</td>\n",
       "      <td>24.6</td>\n",
       "      <td>29.3</td>\n",
       "      <td>61.4</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>20</td>\n",
       "      <td>27.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>63.4</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>22</td>\n",
       "      <td>26.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>64.2</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_name obesity_rank  adults_obesity_rate_2005  \\\n",
       "19        Kentucky            8                      28.4   \n",
       "0          Alabama            5                      30.1   \n",
       "14           Idaho           32                      24.6   \n",
       "35  North Carolina           20                      27.1   \n",
       "45    South Dakota           22                      26.1   \n",
       "\n",
       "    adults_obesity_rate_2020  adults_overweight_rate_2005  \\\n",
       "19                      34.3                         66.8   \n",
       "0                       36.3                         65.4   \n",
       "14                      29.3                         61.4   \n",
       "35                      32.1                         63.4   \n",
       "45                      31.9                         64.2   \n",
       "\n",
       "    children_and_adolescents_obesity_rate_2005  \n",
       "19                                        20.6  \n",
       "0                                         16.7  \n",
       "14                                        10.1  \n",
       "35                                        19.3  \n",
       "45                                        12.1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_states_df = tables_list[0].copy()\n",
    "us_states_df.columns = ['state_name', 'obesity_rank', 'adults_obesity_rate_2005', 'adults_obesity_rate_2020',\n",
    "                                'adults_overweight_rate_2005', 'children_and_adolescents_obesity_rate_2005']\n",
    "def f(x):\n",
    "    rate_float = np.nan\n",
    "    rate_str = str(x)\n",
    "    if '%' in rate_str:\n",
    "        rate_float = float(rate_str.split('%')[0])\n",
    "    \n",
    "    return rate_float\n",
    "for cn in ['adults_obesity_rate_2005', 'adults_obesity_rate_2020',\n",
    "           'adults_overweight_rate_2005', 'children_and_adolescents_obesity_rate_2005']:\n",
    "    us_states_df[cn] = us_states_df[cn].map(f)\n",
    "us_states_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (us_states_df.state_name == 'District of Columbia')\n",
    "us_states_df = us_states_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['American Samoa', 'District of Columbia', 'Guam', 'Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands (U.S.)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove US states duplicates and misspellings\n",
    "states_list = sorted(set(us_states_df.state_name).symmetric_difference(set(ssu.us_stats_df.index)))\n",
    "print(states_list)\n",
    "doubles_df = ssu.check_4_doubles(states_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = us_states_df.duplicated(subset=['state_name'], keep=False)\n",
    "if us_states_df[mask_series].shape[0]:\n",
    "    display(us_states_df[mask_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\obesity_us_states_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(obesity_us_states_df=us_states_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "## Clean and prepare Countries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (191, 3)), (1, (12, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_obesity_rate'\n",
    "# driver = ssu.get_driver()\n",
    "tables_list = ssu.get_page_tables(url, driver=None)\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>obesity_rank</th>\n",
       "      <th>obesity_rate_2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kiribati</td>\n",
       "      <td>9</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Canada</td>\n",
       "      <td>26</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>2</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Mauritius</td>\n",
       "      <td>137</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>156</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country_name  obesity_rank  obesity_rate_2016\n",
       "8             Kiribati             9               46.0\n",
       "25              Canada            26               29.4\n",
       "1         Cook Islands             2               55.9\n",
       "136          Mauritius           137               10.8\n",
       "155  Equatorial Guinea           156                8.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countries_df = tables_list[0].copy()\n",
    "countries_df.columns = ['country_name', 'obesity_rank', 'obesity_rate_2016']\n",
    "countries_df.obesity_rate_2016 = countries_df.obesity_rate_2016.map(lambda x: float(x))\n",
    "countries_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_item</th>\n",
       "      <th>second_item</th>\n",
       "      <th>max_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sint Maarten</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>St. Martin</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bouvet Island</td>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Faroe Islands</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>French Guiana</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_item        second_item  max_similarity\n",
       "8   British Virgin Islands  US Virgin Islands        0.769231\n",
       "10          Cayman Islands      Åland Islands        0.740741\n",
       "48            Sint Maarten         St. Martin        0.727273\n",
       "24                Guernsey             Jersey        0.714286\n",
       "47              San Marino         St. Martin        0.700000\n",
       "6            Bouvet Island      Faroe Islands        0.692308\n",
       "16           Faroe Islands      Åland Islands        0.692308\n",
       "17           French Guiana   French Polynesia        0.620690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Remove country duplicates and misspellings\n",
    "countries_df.country_name = countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "countries_list = sorted(set(countries_df.country_name).symmetric_difference(set(all_countries_df.country_name)))\n",
    "doubles_df = ssu.check_4_doubles(countries_list)\n",
    "mask_series = (doubles_df.max_similarity > 0.6)\n",
    "columns_list = ['first_item', 'second_item', 'max_similarity']\n",
    "if doubles_df[mask_series].shape[0]:\n",
    "    display(doubles_df[mask_series][columns_list].sort_values('max_similarity', ascending=False))\n",
    "mask_series = countries_df.duplicated(subset=['country_name'], keep=False)\n",
    "if countries_df[mask_series].shape[0]:\n",
    "    display(countries_df[mask_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\obesity_countries_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(obesity_countries_df=countries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Prepare for and Create Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_to_country_equivalent_dict, country_to_state_equivalent_dict = ssu.get_country_state_equivalents(countries_df, 'country_name',\n",
    "                                                                                                       'obesity_rate_2016',\n",
    "                                                                                                       us_states_df, 'state_name',\n",
    "                                                                                                       'adults_obesity_rate_2005',\n",
    "                                                                                                       verbose=False)\n",
    "state_to_country_equivalent_dict, country_to_state_equivalent_dict = ssu.get_country_state_equivalents(\n",
    "    countries_df, 'country_name', countries_target_column_name,\n",
    "    us_states_df, 'state_name', states_target_column_name,\n",
    "    cn_col_explanation=None, st_col_explanation=None,\n",
    "    countries_set=None, states_set=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_description_dict['adults_obesity_rate_2020'] = 'Obese adults (2020)'\n",
    "column_description_dict['adults_obesity_rate_2005'] = 'Obese adults (mid-2000s)'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "us_stats_df['Country_Equivalent_Obesity'] = us_stats_df.index.map(lambda x: state_to_country_equivalent_dict.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obesity_dict = us_states_df.set_index('state_name').adults_obesity_rate_2020.to_dict()\n",
    "obesity_min = us_states_df.adults_obesity_rate_2020.min()\n",
    "us_stats_df['adults_obesity_rate_2020'] = us_stats_df.index.map(lambda x: obesity_dict.get(x, obesity_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obesity_dict = us_states_df.set_index('state_name').adults_obesity_rate_2005.to_dict()\n",
    "obesity_min = us_states_df.adults_obesity_rate_2005.min()\n",
    "us_stats_df['adults_obesity_rate_2005'] = us_stats_df.index.map(lambda x: obesity_dict.get(x, obesity_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\svg\\US_adults_obesity_rate_2005_Country_Equivalent_Obesity.svg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c.create_label_line_file()\n",
    "numeric_column_name = 'adults_obesity_rate_2005'\n",
    "string_column_name = 'Country_Equivalent_Obesity'\n",
    "svg_file_path = c.create_country_colored_labeled_map(numeric_column_name=numeric_column_name,\n",
    "                                                     string_column_name=string_column_name,\n",
    "                                                     one_country_df=us_stats_df)\n",
    "print(os.path.abspath(svg_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----\n",
    "# Get State/Country Student Loan Debt Equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (53, 3))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://educationdata.org/student-loan-debt-by-state'\n",
    "tables_list = ssu.get_page_tables(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Average Borrower Debt</th>\n",
       "      <th>State’s Total Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>$37,516</td>\n",
       "      <td>$2.9 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>$34,085</td>\n",
       "      <td>$6.5 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Other/Unspecified*</td>\n",
       "      <td>$25,960</td>\n",
       "      <td>$99.0 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>$33,012</td>\n",
       "      <td>$7.2 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>$41,639</td>\n",
       "      <td>$68.6 billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 State Average Borrower Debt State’s Total Debt\n",
       "10             Vermont               $37,516       $2.9 billion\n",
       "29       New Hampshire               $34,085       $6.5 billion\n",
       "52  Other/Unspecified*               $25,960      $99.0 billion\n",
       "36               Idaho               $33,012       $7.2 billion\n",
       "2              Georgia               $41,639      $68.6 billion"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "student_load_debt_us_states_df = tables_list[0].copy()\n",
    "student_load_debt_us_states_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
       "       'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia',\n",
       "       'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
       "       'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
       "       'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "       'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
       "       'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming'],\n",
       "      dtype='object', name='state_name')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "us_stats_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Choropleths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['district_abbreviation', 'State_Region', 'Google_Suggest_Unique', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First', 'outline_d', 'Country_Equivalent_GDP', 'Country_Equivalent_Military_Expenditure', 'state_color', 'centroid_id']\n",
      "\n",
      "['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent', 'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score', 'Natural_Environment_Score', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005', 'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010', 'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'text_x', 'text_y', 'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight', 'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability', 'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing', 'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'centroid_x', 'centroid_y', 'font_size', 'gdp_millions_usd_2021', 'gdp_millions_usd_2020', 'annual_change_usd', 'annual_change_percentage', 'real_gdp_growth_percentage', 'gdp_per_capita_2021', 'gdp_per_capita_2020', 'national_precentage_2021', 'national_precentage_2020', 'proportion_of_gdp_2021', 'gdp_proportion_of_military_expenditures_2021', 'dy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(c.one_country_df)\n",
    "mask_series = (column_descriptions_df.dtype == 'object')\n",
    "print(column_descriptions_df[mask_series].column_name.tolist())\n",
    "print()\n",
    "print(column_descriptions_df[~mask_series].column_name.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us_stats_df: ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent', 'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score', 'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005', 'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010', 'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'Google_Suggest_Unique', 'text_x', 'text_y', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First', 'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight', 'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability', 'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing', 'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'outline_d', 'centroid_x', 'centroid_y', 'Country_Equivalent_GDP', 'font_size', 'gdp_millions_usd_2021', 'gdp_millions_usd_2020', 'annual_change_usd', 'annual_change_percentage', 'real_gdp_growth_percentage', 'gdp_per_capita_2021', 'gdp_per_capita_2020', 'national_precentage_2021', 'national_precentage_2020', 'proportion_of_gdp_2021', 'gdp_proportion_of_military_expenditures_2021', 'Country_Equivalent_Military_Expenditure', 'state_color', 'centroid_id', 'dy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file_name in os.listdir(s.saves_pickle_folder):\n",
    "    if file_name.endswith('_df.pkl'):\n",
    "        df_name = file_name.split('.')[0]\n",
    "        df = s.load_object(df_name)\n",
    "        columns_list = df.columns.tolist()\n",
    "        if 'district_abbreviation' in columns_list:\n",
    "            print(f'{df_name}: {columns_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "inkscape_path = r'C:\\Program Files\\Inkscape\\bin\\inkscape.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Estimated_IQ'\n",
    "if column_name in us_stats_df.columns:\n",
    "    svg_file_path = c.create_country_colored_map(column_name)\n",
    "    !\"{text_editor_path}\" \"{os.path.abspath(svg_file_path)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'White_Percent'\n",
    "if column_name in us_stats_df.columns:\n",
    "    svg_file_path = os.path.abspath(c.create_country_colored_map(column_name))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\"\n",
    "    # !\"{inkscape_path}\" window-open \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Percent_Whites_in_Non_Public_Education'\n",
    "if column_name in us_stats_df.columns:\n",
    "    svg_file_path = os.path.abspath(c.create_country_colored_map(column_name))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\"\n",
    "    # !\"{inkscape_path}\" window-open \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'centroid_id' not in us_stats_df.columns:\n",
    "    us_stats_df['centroid_id'] = us_stats_df.index.map(lambda x: ('district-' + c.indexize_string(x)).replace('-district', ''))\n",
    "    s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'dy' not in us_stats_df.columns:\n",
    "    us_stats_df['dy'] = np.nan\n",
    "    s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "string_column_name = 'State_Region'\n",
    "if string_column_name in us_stats_df.columns:\n",
    "    c.create_label_line_file()\n",
    "    svg_file_path = os.path.abspath(c.create_country_labeled_map(string_column_name=string_column_name,\n",
    "                                                                 one_country_df=c.one_country_df))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\"\n",
    "    !\"{inkscape_path}\" window-open \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_column_name = 'Asian_Percent'\n",
    "string_column_name = 'Google_Suggest_Common'\n",
    "if (numeric_column_name in us_stats_df.columns) and (string_column_name in us_stats_df.columns):\n",
    "    svg_file_path = os.path.abspath(c.create_country_colored_labeled_map(numeric_column_name=numeric_column_name,\n",
    "                                                                         string_column_name=string_column_name,\n",
    "                                                                         one_country_df=c.one_country_df))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_color_dict = s.load_object('us_state_name_color_dict')\n",
    "string_column_name = 'Google_Suggest_First'\n",
    "if string_column_name in us_stats_df.columns:\n",
    "    svg_file_path = os.path.abspath(c.create_country_labeled_map(string_column_name=string_column_name,\n",
    "                                                                 one_country_df=c.one_country_df))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "ListedColormap_obj = cm.get_cmap('viridis', len(c.one_country_df.State_Budget_Processes.unique()))\n",
    "min = c.one_country_df.State_Budget_Processes.min()\n",
    "max = c.one_country_df.State_Budget_Processes.max()\n",
    "normed_series = (c.one_country_df.State_Budget_Processes - min) / (max - min)\n",
    "sample_value = normed_series.sample(1).tolist()[0]\n",
    "if str(sample_value) != 'nan':\n",
    "    print(ListedColormap_obj(sample_value), '#{:02x}{:02x}{:02x}{:02x}'.format(*tuple(int(x*255) for x in ListedColormap_obj(sample_value))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['c.one_country_df.{}'.format(fn) for fn in dir(c.one_country_df) if 'sort' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!start %windir%\\explorer.exe \"{c.svg_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in c.one_country_df.columns:\n",
    "    svg_file_path = c.create_country_colored_map(column_name=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['c.one_country_df.{}'.format(cn) for cn in c.one_country_df.columns if ('gun' in cn.lower()) and ('murder' in cn.lower())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# O Canada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22, (140, 8)), (14, (122, 9)), (26, (78, 2)), (27, (37, 2)), (4, (28, 11)), (0, (26, 2)), (5, (25, 12)), (28, (25, 2)), (17, (24, 3)), (13, (22, 5)), (35, (21, 2)), (12, (18, 11)), (25, (18, 3)), (18, (17, 11)), (1, (14, 11)), (41, (13, 2)), (16, (11, 3)), (2, (10, 10)), (3, (10, 10)), (6, (8, 3)), (20, (8, 5)), (10, (7, 3)), (7, (6, 3)), (8, (6, 3)), (23, (6, 3)), (24, (6, 3)), (32, (6, 2)), (11, (5, 3)), (21, (5, 5)), (29, (5, 2)), (31, (5, 2)), (9, (4, 3)), (19, (4, 11)), (34, (4, 2)), (15, (3, 4)), (30, (3, 2)), (33, (3, 2)), (36, (2, 2)), (37, (2, 2)), (38, (2, 2)), (39, (2, 2)), (40, (2, 2)), (42, (2, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "page_tables_list = ssu.get_page_tables('https://en.wikipedia.org/wiki/Demographics_of_Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "canada_races_df = page_tables_list[14].copy()\n",
    "canada_races_df.columns = [cn.split('[')[0].strip() for cn in canada_races_df.columns.droplevel(0).tolist()]\n",
    "canada_races_df['Province/territory'] = canada_races_df['Province/territory'].map(lambda cn: cn.split('[')[0])\n",
    "canada_races_df.set_index('Province/territory', drop=True, inplace=True)\n",
    "canada_races_df['Percent visible minority'] = canada_races_df['Percent visible minority'].map(lambda x: float(str(x).split('%')[0]))\n",
    "canada_races_df['Percent_White'] = canada_races_df['Percent visible minority'].map(lambda x: 100.0 - x)\n",
    "canada_races_df.dropna(axis='columns', how='all', inplace=True)\n",
    "canada_races_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(canada_races_df=canada_races_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Add New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.columns = ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent',\n",
    "                       'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score',\n",
    "                       'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score',\n",
    "                       'Crime_Corrections_Score', 'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018',\n",
    "                       'GDP_Percent', 'State_Region', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014',\n",
    "                       'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank',\n",
    "                       'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016',\n",
    "                       'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014',\n",
    "                       'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005',\n",
    "                       'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010',\n",
    "                       'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010',\n",
    "                       'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'Google_Suggest_Unique', 'text_x',\n",
    "                       'text_y', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First',\n",
    "                       'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight',\n",
    "                       'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability',\n",
    "                       'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing',\n",
    "                       'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'outline_d',\n",
    "                       'centroid_x', 'centroid_y']\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "file_path = os.path.join(s.data_folder, 'svg', 'us.svg')\n",
    "#print(['root.{}'.format(fn) for fn in dir(root) if not fn.startswith('_')])\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "root = et.parse(file_path).getroot()\n",
    "outline_d_dict = {}\n",
    "for tag in root:\n",
    "    if (tag.tag.split('}')[-1] == 'path'):\n",
    "        #print(['tag.{}'.format(fn) for fn in dir(tag) if not fn.startswith('_')])\n",
    "        state_name = tag.attrib['data-name']\n",
    "        outline_d = tag.attrib['d']\n",
    "        outline_d_dict[state_name] = outline_d\n",
    "\n",
    "df = pd.DataFrame([outline_d_dict]).T\n",
    "df.columns = ['outline_d']\n",
    "us_stats_df = us_stats_df.T.append(df.T).T\n",
    "us_stats_df.T.tail(5).T.sample(7).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = 'State_Integrity_2015_Full_Dataset.xlsx'\n",
    "excel_path = os.path.join(s.data_folder, 'xlsx', file_name)\n",
    "sheet_df_dict = pd.read_excel(excel_path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "for sheet_name in sheet_df_dict.keys():\n",
    "    column_name = '_'.join(sheet_name.strip().split(' '))\n",
    "    df = sheet_df_dict[sheet_name].copy()\n",
    "    index_columns = df.loc[0, ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']].tolist()\n",
    "    df.columns = index_columns + df.columns.tolist()[3:]\n",
    "    df.set_index(keys=index_columns, inplace=True)\n",
    "    cn_dict = {}\n",
    "    for state_name in us_stats_df.index:\n",
    "        cn_dict[state_name] = []\n",
    "    for index_tuple, row_series in df[states_list].iterrows():\n",
    "        if str(index_tuple[1]).isdigit():\n",
    "            #print(index_tuple)\n",
    "            for state_name, column_value in row_series.iteritems():\n",
    "                state_name = state_name.strip()\n",
    "                column_value = column_value.strip()\n",
    "                if str(column_value).isdigit():\n",
    "                    scores_list = cn_dict[state_name]\n",
    "                    scores_list.append(column_value)\n",
    "                    cn_dict[state_name] = scores_list\n",
    "                elif column_value.lower() in ['no', 'moderate', 'yes']:\n",
    "                    scores_list = cn_dict[state_name]\n",
    "                    scores_list.append(['no', 'moderate', 'yes'].index(column_value.lower())*50)\n",
    "                    cn_dict[state_name] = scores_list\n",
    "    cn_dict = {state_name: sum([b/len(scores_list) for b in scores_list]) for state_name,\n",
    "               scores_list in cn_dict.items()}\n",
    "    df = pd.DataFrame([cn_dict]).T\n",
    "    df.columns = [column_name]\n",
    "    us_stats_df = us_stats_df.T.append(df.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.T.tail(20).T.sample(8).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Get Correlations (\"P-Hunting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_correlation_dataframe(numeric_columns_list):\n",
    "    rows_list = []\n",
    "    for x_column in numeric_columns_list:\n",
    "        for y_column in numeric_columns_list:\n",
    "            if x_column != y_column:\n",
    "                columns_list = [x_column, y_column]\n",
    "                df = us_stats_df[columns_list].dropna()\n",
    "                x = df[x_column].values\n",
    "                y = df[y_column].values\n",
    "                try:\n",
    "                    r_tuple = stats.pearsonr(x, y)\n",
    "                    if r_tuple[1] < 0.05:\n",
    "                        row_dict = {}\n",
    "                        row_dict['left_column'] = x_column\n",
    "                        row_dict['right_column'] = y_column\n",
    "                        row_dict['pearson_r'] = abs(r_tuple[0])\n",
    "                        rows_list.append(row_dict)\n",
    "                except Exception as e:\n",
    "                    print('{} and {} get an error: {}'.format(x_column, y_column, e))\n",
    "    correlation_df = pd.DataFrame(rows_list, columns=['left_column', 'right_column', 'pearson_r'])\n",
    "    \n",
    "    return correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(df=us_stats_df)\n",
    "column_descriptions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (column_descriptions_df.dtype == 'float32')\n",
    "columns_list = [row_series.column_name for row_index, row_series in column_descriptions_df[mask_series].iterrows()]\n",
    "correlation_df = get_correlation_dataframe(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (correlation_df.pearson_r > 0.95)\n",
    "correlation_df[mask_series].sort_values('pearson_r', ascending=False).left_column.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_correlation_dataframe(x_column_list, y_column_list):\n",
    "    rows_list = []\n",
    "    for x_column in x_column_list:\n",
    "        for y_column in y_column_list:\n",
    "            if x_column != y_column:\n",
    "                columns_list = [x_column, y_column]\n",
    "                df = us_stats_df[columns_list].dropna()\n",
    "                x = df[x_column].values\n",
    "                y = df[y_column].values\n",
    "                try:\n",
    "                    r_tuple = stats.pearsonr(x, y)\n",
    "                    if r_tuple[1] < 0.05:\n",
    "                        row_dict = {}\n",
    "                        row_dict['left_column'] = x_column\n",
    "                        row_dict['right_column'] = y_column\n",
    "                        row_dict['pearson_r'] = abs(r_tuple[0])\n",
    "                        rows_list.append(row_dict)\n",
    "                except Exception as e:\n",
    "                    print('{} and {} get an error: {}'.format(x_column, y_column, e))\n",
    "    correlation_df = pd.DataFrame(rows_list, columns=['left_column', 'right_column', 'pearson_r'])\n",
    "    \n",
    "    return correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (column_descriptions_df.dtype == 'float32')\n",
    "numeric_columns_list = [row_series.column_name for row_index, row_series in column_descriptions_df[mask_series].iterrows()]\n",
    "new_columns_list = us_stats_df.T.tail(13).index.tolist()\n",
    "old_columns_list = list(set(numeric_columns_list) - set(new_columns_list))\n",
    "correlation_df = get_correlation_dataframe(new_columns_list, old_columns_list)\n",
    "correlation_df.sort_values('pearson_r', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Linear Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_linear_scatterplot(merged_df, columns_list, ev_min_str=None, ev_max_str=None, rv_min_str=None, rv_max_str=None):\n",
    "    ev_column_name = columns_list[0]\n",
    "    rv_column_name = columns_list[1]\n",
    "    explanatory_variable = get_column_description(ev_column_name)\n",
    "    response_variable = get_column_description(rv_column_name)\n",
    "    if (ev_min_str is None):\n",
    "        ev_min_str = 'minimum {}'.format(explanatory_variable)\n",
    "    if (ev_max_str is None):\n",
    "        ev_max_str = 'maximum {}'.format(explanatory_variable)\n",
    "    if (rv_min_str is None):\n",
    "        rv_min_str = 'minimum {}'.format(response_variable)\n",
    "    if (rv_max_str is None):\n",
    "        rv_max_str = 'maximum {}'.format(response_variable)\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    columns_list = [ev_column_name, rv_column_name]\n",
    "    df = df[columns_list].dropna()\n",
    "    ev_max = df[ev_column_name].max()\n",
    "    ev_min = df[ev_column_name].min()\n",
    "    rv_min = df[rv_column_name].min()\n",
    "    rv_max = df[rv_column_name].max()\n",
    "    ev_max_labeled = False\n",
    "    ev_min_labeled = False\n",
    "    rv_min_labeled = False\n",
    "    rv_max_labeled = False\n",
    "    \n",
    "    # First order (linear) scatterplot\n",
    "    fig1_fig = plt.figure(figsize=(12, 8))\n",
    "    merge_axes_subplot = sns.regplot(x=ev_column_name, y=rv_column_name,\n",
    "                                     scatter=True, data=df)\n",
    "    xlabel_text = plt.xlabel('{} (explanatory variable)'.format(explanatory_variable))\n",
    "    ylabel_text = plt.ylabel('{} (response variable)'.format(response_variable))\n",
    "    \n",
    "    # Add annotations\n",
    "    for label, x, y in zip(df.index, df[ev_column_name], df[rv_column_name]):\n",
    "        if (x == ev_min):\n",
    "            if not ev_min_labeled:\n",
    "                ev_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_min_str), xy=(x, y), xytext=ev_min_xytext, **kwargs)\n",
    "        elif (x == ev_max):\n",
    "            if not ev_max_labeled:\n",
    "                ev_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_max_str), xy=(x, y), xytext=ev_max_xytext, **kwargs)\n",
    "        elif (y == rv_min):\n",
    "            if not rv_min_labeled:\n",
    "                rv_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_min_str), xy=(x, y), xytext=rv_min_xytext, **kwargs)\n",
    "        elif (y == rv_max):\n",
    "            if not rv_max_labeled:\n",
    "                rv_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_max_str), xy=(x, y), xytext=rv_max_xytext, **kwargs)\n",
    "        elif (label == 'Arizona'):\n",
    "            annotation = plt.annotate('{} (my home state)'.format(label), xy=(x, y), xytext=az_xytext, **kwargs)\n",
    "    \n",
    "    # Add r-squared\n",
    "    x = df[ev_column_name].values\n",
    "    y = df[rv_column_name].values\n",
    "    plt.text(0.92, 0.965, r'$r^2 = {0:.2}$'.format(stats.pearsonr(x, y)[0] ** 2), fontsize=20, alpha=0.25,\n",
    "             horizontalalignment='center', verticalalignment='center', transform=merge_axes_subplot.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_column_description(column_name):\n",
    "    if column_name in column_description_dict:\n",
    "        column_description = column_description_dict[column_name]\n",
    "    else:\n",
    "        column_description = re.sub('^pf_', 'Personal Freedom:_', str(column_name), 1)\n",
    "        column_description = re.sub('^hf_', 'Human Freedom:_', str(column_description), 1)\n",
    "        column_description = re.sub('^ef_', 'Economic Freedom:_', str(column_description), 1)\n",
    "        column_list = column_description.split('_')\n",
    "        descr_list = []\n",
    "        for word in column_list:\n",
    "            descr_list.append(word[0].upper()+word[1:])\n",
    "        column_description = ' '.join(descr_list)\n",
    "        column_description_dict[column_name] = column_description\n",
    "        s.store_objects(column_description_dict=column_description_dict)\n",
    "    \n",
    "    return column_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'State_Budget_Processes'\n",
    "\n",
    "rv_column_name = 'Homicide_Rate_2018'\n",
    "\n",
    "ev_min_str = 'worst process'\n",
    "ev_max_str = 'best process'\n",
    "rv_min_str = 'least murderous'\n",
    "rv_max_str = 'most murderous'\n",
    "ev_min_xytext = (-5, -40)\n",
    "ev_max_xytext = (-100, -40)\n",
    "rv_min_xytext = (-45, -35)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (0, 30)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_df = get_correlation_dataframe(new_columns_list, new_columns_list)\n",
    "correlation_df.sort_values('pearson_r', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Executive_Accountability'\n",
    "\n",
    "rv_column_name = 'Legislative_Accountability'\n",
    "\n",
    "ev_min_str = 'least executive accountability'\n",
    "ev_max_str = 'most executive accountability'\n",
    "rv_min_str = 'least legislative accountability'\n",
    "rv_max_str = 'most legislative accountability'\n",
    "ev_min_xytext = (15, 5)\n",
    "ev_max_xytext = (-210, -30)\n",
    "rv_min_xytext = (-45, -35)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-15, 10)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "rv_column_name = 'Suicide_Deaths_2017'\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least suicidal'\n",
    "rv_max_str = 'most suicidal'\n",
    "ev_min_xytext = (50, -10)\n",
    "ev_max_xytext = (-150, -60)\n",
    "rv_min_xytext = (20, -15)\n",
    "rv_max_xytext = (100, -50)\n",
    "az_xytext = (60, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "df = us_stats_df[columns_list+['Total_Inhabitants_2010']].copy()\n",
    "df[ev_column_name] = df[ev_column_name]/df['Total_Inhabitants_2010']\n",
    "df[rv_column_name] = df[rv_column_name]/df['Total_Inhabitants_2010']\n",
    "mask_series = (df.index == 'Wyoming')\n",
    "show_linear_scatterplot(df[~mask_series], columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (52, 8)), (0, (50, 4))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "tables_url = 'https://en.wikipedia.org/wiki/Firearm_death_rates_in_the_United_States_by_state'\n",
    "tables_df_list = ssu.get_page_tables(tables_url, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.district_abbreviation.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gun_murders_df = tables_df_list[4].copy()\n",
    "gun_murders_df.set_index('State', inplace=True)\n",
    "print(gun_murders_df.columns.tolist())\n",
    "gun_murders_df.columns = ['Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010',\n",
    "                          'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010',\n",
    "                          'Gun_Murder_Rate_2010']\n",
    "gun_murders_df.Gun_Ownership_Percent_2013 = gun_murders_df.Gun_Ownership_Percent_2013.map(lambda x: float(str(x).split('%')[0]))\n",
    "gun_murders_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gun_suicides_df = s.load_csv(csv_name='gun_suicides_by_state',\n",
    "                             folder_path=s.data_folder).dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "gun_suicides_df = gun_suicides_df.iloc[11:].dropna(axis=1, how='all')\n",
    "abbrev_dict = {row_series.district_abbreviation: state_name for state_name, row_series in us_stats_df.iterrows()}\n",
    "abbrev_dict['DC'] = 'District of Columbia'\n",
    "gun_suicides_df.ST = gun_suicides_df.ST.map(lambda x: abbrev_dict[x])\n",
    "gun_suicides_df.columns = ['State', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate']\n",
    "gun_suicides_df.set_index('State', inplace=True)\n",
    "gun_suicides_df.Gun_Suicide_Rate = gun_suicides_df.Gun_Suicide_Rate.map(lambda x: float(x))\n",
    "for column_name in ['State_FIPS', 'State_Population', 'Gun_Suicide_Deaths']:\n",
    "    gun_suicides_df[column_name] = gun_suicides_df[column_name].map(lambda x: int(x))\n",
    "gun_suicides_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set(gun_merge_df.columns).intersection(set(us_stats_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent',\n",
    "                'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score',\n",
    "                'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score',\n",
    "                'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region',\n",
    "                'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005',\n",
    "                'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered',\n",
    "                'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015',\n",
    "                'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005']\n",
    "us_stats_df = pd.merge(left=us_stats_df[columns_list], right=gun_merge_df, left_index=True,\n",
    "                          right_index=True, suffixes=('_merge', '_guns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(df=us_stats_df, column_list=us_stats_df.columns)\n",
    "mask_series = (column_descriptions_df.dtype.isin(['int64', 'float64']))\n",
    "print(column_descriptions_df[~mask_series].column_name.tolist())\n",
    "column_descriptions_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(us_stats_df)\n",
    "column_descriptions_df['dtype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (column_descriptions_df['dtype'].isin(['int64', 'float64']))\n",
    "numeric_columns_list = column_descriptions_df[mask_series]['column_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in numeric_columns_list:\n",
    "    us_stats_df[column_name] = pd.to_numeric(us_stats_df[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "r_columns_list = []\n",
    "rows_list = []\n",
    "for x_column in numeric_columns_list:\n",
    "    for y_column in numeric_columns_list:\n",
    "        if x_column != y_column:\n",
    "            columns_list = [x_column, y_column]\n",
    "            df = us_stats_df[columns_list].dropna()\n",
    "            x = df[x_column].values\n",
    "            y = df[y_column].values\n",
    "            try:\n",
    "                r_tuple = stats.pearsonr(x, y)\n",
    "                if r_tuple[1] < 0.05:\n",
    "                    c_tuple = ('/'.join(columns_list), row_dict['pearson_r'])\n",
    "                    r_columns_list.append(c_tuple)\n",
    "            except Exception as e:\n",
    "                print('{} and {} get an error: {}'.format(x_column, y_column, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_pairs_list = sorted(r_columns_list, key=lambda x: x[1], reverse=True)\n",
    "[column_pairs_list[0][0].split('/')[0], column_pairs_list[0][0].split('/')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "column_description_dict[ev_column_name] = 'Number of Guns Registered'\n",
    "#s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "rv_column_name = 'Gun_Murder_Rate_2010'\n",
    "column_description_dict[rv_column_name] = 'Gun Murder Rate'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least murderous'\n",
    "rv_max_str = 'most murderous'\n",
    "ev_min_xytext = (-5, 90)\n",
    "ev_max_xytext = (-130, -60)\n",
    "rv_min_xytext = (20, -15)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-60, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "%run ../load_magic/dataframes.py\n",
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "column_description_dict[ev_column_name] = 'Number of Guns Registered'\n",
    "#s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "rv_column_name = 'Gun_Suicide_Deaths'\n",
    "column_description_dict[rv_column_name] = 'Gun Suicide Deaths'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least suicidal'\n",
    "rv_max_str = 'most suicidal'\n",
    "ev_min_xytext = (-5, 110)\n",
    "ev_max_xytext = (-130, -60)\n",
    "rv_min_xytext = (20, -30)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-60, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_list = []\n",
    "for row_index, row_series in correlation_df.sort_values('pearson_r', ascending=False).iterrows():\n",
    "    left_column = row_series['left_column']\n",
    "    right_column = row_series['right_column']\n",
    "    if ('gun' in left_column.lower()) or ('gun' in right_column.lower()):\n",
    "        rows_list.append(row_series.to_dict())\n",
    "pd.DataFrame(rows_list).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_list = []\n",
    "for row_index, row_series in correlation_df.sort_values('pearson_r', ascending=False).iterrows():\n",
    "    left_column = row_series['left_column']\n",
    "    right_column = row_series['right_column']\n",
    "    if ('gun' in left_column.lower()) or ('gun' in right_column.lower()):\n",
    "        rows_list.append(row_series.to_dict())\n",
    "pd.DataFrame(rows_list).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['row_series.{}'.format(fn) for fn in dir(row_series) if 'dict' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (52, 3))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tables_url = 'https://www.thoughtco.com/gun-owners-percentage-of-state-populations-3325153'\n",
    "tables_df_list = ssu.get_page_tables(tables_url, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nutty_df = tables_df_list[0].dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "nutty_df.columns = ['Guns_Rank', 'State', 'Guns_Per_Capita', 'Guns_Registered']\n",
    "nutty_df = nutty_df.iloc[1:]\n",
    "nutty_df.set_index('State', inplace=True)\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=nutty_df, left_index=True,\n",
    "                          right_index=True, suffixes=('_merge', '_nutty'))\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suicide_df = s.load_csv(csv_name='Suicide Mortality by State',\n",
    "                        folder_path=s.data_folder).dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "columns_list = ['Suicide_Year', 'district_abbreviation', 'Suicide_Rate', 'Suicide_Deaths']\n",
    "suicide_df.columns = columns_list + ['URL']\n",
    "suicide_df = suicide_df[columns_list]\n",
    "suicide_df.Suicide_Year = suicide_df.Suicide_Year.map(lambda x: int(x))\n",
    "suicide_df = s.load_csv(csv_name='Suicide Mortality by State',\n",
    "                        folder_path=s.data_folder).dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "suicide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year in suicide_df.Suicide_Year.unique():\n",
    "    mask_series = (suicide_df.Suicide_Year == year)\n",
    "    df = suicide_df[mask_series]\n",
    "    columns_list = ['district_abbreviation', 'Suicide_Rate_{}'.format(year),\n",
    "                    'Suicide_Deaths_{}'.format(year)]\n",
    "    df.columns = ['Suicide_Year'] + columns_list\n",
    "    df = df[columns_list]\n",
    "    us_stats_df = pd.merge(left=us_stats_df, right=df, how='inner', on='district_abbreviation', suffixes=('_merge', '_suicide'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(us_stats_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "for column_name in ['Guns_Rank', 'Guns_Registered']:\n",
    "    us_stats_df[column_name] = us_stats_df[column_name].map(lambda x: int(x))\n",
    "us_stats_df.Guns_Per_Capita = us_stats_df.Guns_Per_Capita.map(lambda x: float(x))\n",
    "for year in [2005, 2014, 2015, 2016, 2017]:\n",
    "    for infix in ['Rate', 'Deaths']:\n",
    "        column_name = 'Suicide_{}_{}'.format(infix, year)\n",
    "        us_stats_df[column_name] = us_stats_df[column_name].map(lambda x: int(re.sub(r'[^0-9\\.]+', '', str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.Suicide_Deaths_2017.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (60, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#us_stats_df['district_abbreviation']\n",
    "file_path = os.path.join(s.data_folder, 'html', 'us_state_abbreviations.html')\n",
    "#tables_url = 'https://www.50states.com/abbreviations.htm'\n",
    "tables_df_list = ssu.get_page_tables(file_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abbrevs_df = tables_df_list[0].dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "abbrevs_df.columns = ['State', 'district_abbreviation']\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=abbrevs_df, on='district_abbreviation', suffixes=('_merge', '_abbrevs'))\n",
    "us_stats_df.set_index('State', inplace=True)\n",
    "us_stats_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016',\n",
    "                'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014',\n",
    "                'Suicide_Rate_2005', 'Suicide_Deaths_2005']\n",
    "ssu.get_column_descriptions(df=us_stats_df, column_list=columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_max_rsquared_adj(df=us_stats_df, columns_list=columns_list,\n",
    "                     verbose=False).sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following only if you are on a high definition device\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "basecolor_list = list(mcolors.BASE_COLORS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "%run ../load_magic/dataframes.py\n",
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "column_description_dict[ev_column_name] = 'Number of Guns Registered'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "rv_column_name = 'Suicide_Deaths_2017'\n",
    "column_description_dict[rv_column_name] = 'Suicide Deaths in 2017'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least suicidal'\n",
    "rv_max_str = 'most suicidal'\n",
    "ev_min_xytext = (-5, 150)\n",
    "ev_max_xytext = (-130, -100)\n",
    "rv_min_xytext = (20, -30)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-80, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tables_url = 'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_GDP'\n",
    "tables_df_list = pd.read_html(tables_url)\n",
    "print([(i, df.shape) for (i, df) in enumerate(tables_df_list) if df.shape[0] > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_gdps_df = tables_df_list[2].dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "state_gdps_df.columns = ['Rank', 'State', '2018', '% of Nation', 'Region']\n",
    "state_gdps_df = state_gdps_df.iloc[1:]\n",
    "state_gdps_df.set_index('State', inplace=True)\n",
    "for column_name in ['Rank', '2018']:\n",
    "    state_gdps_df[column_name] = state_gdps_df[column_name].map(lambda x: int(str(x).split('[')[0]))\n",
    "for column_name in ['% of Nation']:\n",
    "    state_gdps_df[column_name] = state_gdps_df[column_name].map(lambda x: float(str(x).split('[')[0]))\n",
    "for column_name in ['Region']:\n",
    "    state_gdps_df[column_name] = state_gdps_df[column_name].map(lambda x: str(x).split('[')[0])\n",
    "state_gdps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df = load_object('us_stats_df')\n",
    "print(us_stats_df.shape, state_gdps_df.shape)\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=state_gdps_df, left_index=True, right_index=True, suffixes=('_merge', '_gdp'))\n",
    "print(us_stats_df.shape)\n",
    "us_stats_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.columns = ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent',\n",
    "                          'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score',\n",
    "                          'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score',\n",
    "                          'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region']\n",
    "store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following only if you are on a high definition device\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "explanatory_variable = 'Effectiveness Rank'\n",
    "ev_column_name = 'Effectiveness_Rank'\n",
    "response_variable = 'GDP Rank'\n",
    "rv_column_name = 'GDP_Rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = us_stats_df.copy()\n",
    "ev_min_str = 'most effective'\n",
    "ev_max_str = 'least effective'\n",
    "rv_min_str = 'highest GDP'\n",
    "rv_max_str = 'lowest GDP'\n",
    "ev_min_xytext = (-5, 150)\n",
    "ev_max_xytext = (-135, -30)\n",
    "rv_min_xytext = (20, -10)\n",
    "rv_max_xytext = (-100, -50)\n",
    "us_xytext = (-90, 40)\n",
    "\n",
    "fig1_fig = plt.figure(figsize=(12,8))\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "df = df[columns_list].dropna()\n",
    "\n",
    "# First order (linear) scatterplot\n",
    "merge_axes_subplot = sns.regplot(x=ev_column_name, y=rv_column_name,\n",
    "                                 scatter=True, data=df)\n",
    "xlabel_text = plt.xlabel('{} (explanatory variable)'.format(explanatory_variable))\n",
    "ylabel_text = plt.ylabel('{} (response variable)'.format(response_variable))\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "ev_max = df[ev_column_name].max()\n",
    "ev_min = df[ev_column_name].min()\n",
    "rv_min = df[rv_column_name].min()\n",
    "rv_max = df[rv_column_name].max()\n",
    "for label, x, y in zip(df.index, df[ev_column_name], df[rv_column_name]):\n",
    "    if (x == ev_min):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, ev_min_str), xy=(x, y), xytext=ev_min_xytext, **kwargs)\n",
    "    elif (x == ev_max):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, ev_max_str), xy=(x, y), xytext=ev_max_xytext, **kwargs)\n",
    "    elif (y == rv_min):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, rv_min_str), xy=(x, y), xytext=rv_min_xytext, **kwargs)\n",
    "    elif (y == rv_max):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, rv_max_str), xy=(x, y), xytext=rv_max_xytext, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tables_url = 'https://en.wikipedia.org/wiki/List_of_U.S._states_by_homicide_rate'\n",
    "tables_df_list = pd.read_html(tables_url)\n",
    "print([(i, df.shape) for (i, df) in enumerate(tables_df_list) if df.shape[0] >= 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "homicide_df = tables_df_list[0]\n",
    "homicide_df.set_index('State', inplace=True)\n",
    "for column_name in homicide_df.columns:\n",
    "    homicide_df[column_name] = homicide_df[column_name].map(lambda x: float(x))\n",
    "homicide_df.columns = ['Homicide_Rate_{}'.format(cn) for cn in homicide_df.columns]\n",
    "homicide_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(us_stats_df.shape, homicide_df.shape)\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=homicide_df, left_index=True, right_index=True, suffixes=('_merge', '_homicide'))\n",
    "print(us_stats_df.shape)\n",
    "us_stats_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following only if you are on a high definition device\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "explanatory_variable = 'Percent Black'\n",
    "ev_column_name = 'Black_Percent'\n",
    "response_variable = 'Homicide Rate 2014'\n",
    "rv_column_name = 'Homicide_Rate_2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_linear_scatterplot(merged_df, columns_list, ev_min_str=None, ev_max_str=None, rv_min_str=None, rv_max_str=None):\n",
    "    ev_column_name = columns_list[0]\n",
    "    rv_column_name = columns_list[1]\n",
    "    explanatory_variable = get_column_description(ev_column_name)\n",
    "    response_variable = get_column_description(rv_column_name)\n",
    "    if (ev_min_str is None):\n",
    "        ev_min_str = 'minimum {}'.format(explanatory_variable)\n",
    "    if (ev_max_str is None):\n",
    "        ev_max_str = 'maximum {}'.format(explanatory_variable)\n",
    "    if (rv_min_str is None):\n",
    "        rv_min_str = 'minimum {}'.format(response_variable)\n",
    "    if (rv_max_str is None):\n",
    "        rv_max_str = 'maximum {}'.format(response_variable)\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    columns_list = [ev_column_name, rv_column_name]\n",
    "    df = df[columns_list].dropna()\n",
    "    ev_max = df[ev_column_name].max()\n",
    "    ev_min = df[ev_column_name].min()\n",
    "    rv_min = df[rv_column_name].min()\n",
    "    rv_max = df[rv_column_name].max()\n",
    "    ev_max_labeled = False\n",
    "    ev_min_labeled = False\n",
    "    rv_min_labeled = False\n",
    "    rv_max_labeled = False\n",
    "    \n",
    "    # First order (linear) scatterplot\n",
    "    fig1_fig = plt.figure(figsize=(12,8))\n",
    "    merge_axes_subplot = sns.regplot(x=ev_column_name, y=rv_column_name,\n",
    "                                     scatter=True, data=df)\n",
    "    xlabel_text = plt.xlabel('{} (explanatory variable)'.format(explanatory_variable))\n",
    "    ylabel_text = plt.ylabel('{} (response variable)'.format(response_variable))\n",
    "    \n",
    "    # Add annotations\n",
    "    for label, x, y in zip(df.index, df[ev_column_name], df[rv_column_name]):\n",
    "        if (x == ev_min):\n",
    "            if not ev_min_labeled:\n",
    "                ev_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_min_str), xy=(x, y), xytext=ev_min_xytext, **kwargs)\n",
    "        elif (x == ev_max):\n",
    "            if not ev_max_labeled:\n",
    "                ev_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_max_str), xy=(x, y), xytext=ev_max_xytext, **kwargs)\n",
    "        elif (y == rv_min):\n",
    "            if not rv_min_labeled:\n",
    "                rv_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_min_str), xy=(x, y), xytext=rv_min_xytext, **kwargs)\n",
    "        elif (y == rv_max):\n",
    "            if not rv_max_labeled:\n",
    "                rv_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_max_str), xy=(x, y), xytext=rv_max_xytext, **kwargs)\n",
    "        elif (label == 'Arizona'):\n",
    "            annotation = plt.annotate('{} (my home state)'.format(label), xy=(x, y), xytext=az_xytext, **kwargs)\n",
    "    \n",
    "    # Add r-squared\n",
    "    x = df[ev_column_name].values\n",
    "    y = df[rv_column_name].values\n",
    "    plt.text(0.92, 0.965, r'$r^2 = {0:.2}$'.format(stats.pearsonr(x, y)[0] ** 2), fontsize=20, alpha=0.25,\n",
    "             horizontalalignment='center', verticalalignment='center', transform=merge_axes_subplot.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "us_stats_df = load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "ev_min_str = 'least black'\n",
    "ev_max_str = 'most black'\n",
    "rv_min_str = 'least murderous'\n",
    "rv_max_str = 'most murderous'\n",
    "ev_min_xytext = (-5, 150)\n",
    "ev_max_xytext = (-130, -100)\n",
    "rv_min_xytext = (20, -10)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-80, 60)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str, ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Total_Gun_Murder_Deaths_2010'\n",
    "cb1 = c.show_colorbar(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.pyplot import savefig\n",
    "\n",
    "savefig??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print([f'cb1.{fn}' for fn in dir(cb1) if 'fig' in fn.lower()])\n",
    "print([f'cb1.{fn}' for fn in dir(cb1) if 'ax' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(1, 6))\n",
    "print([f'plt.{fn}' for fn in dir(plt) if 'fig' in fn.lower()])\n",
    "print([f'plt.{fn}' for fn in dir(plt) if 'ax' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as fga\n",
    "\n",
    "canvas_obj = fga(figure=fig)\n",
    "print([f'fga.{fn}' for fn in dir(fga) if not fn.startswith('_')])\n",
    "print([f'canvas_obj.{fn}' for fn in dir(canvas_obj) if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'Estimated_IQ' not in us_stats_df.columns:\n",
    "    if s.csv_exists('iq_by_us_state'):\n",
    "        iq_by_us_state_df = s.load_csv('iq_by_us_state')\n",
    "        iq_by_us_state_df.set_index('State', drop=True, inplace=True)\n",
    "        iq_by_us_state_df.columns = ['Estimated_IQ', 'Percent_Whites_in_Non_Public_Education', 'Gross_Product', 'Health', 'Violent_Crime',\n",
    "                                     'Government_Effectiveness']\n",
    "        us_stats_df = pd.merge(left=us_stats_df, right=iq_by_us_state_df, how='outer', left_index=True,\n",
    "                               right_index=True, suffixes=('_stats', '_iq'))\n",
    "        s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if notebook_path is not None:\n",
    "    !start %windir%\\explorer.exe \"{os.path.abspath(os.path.dirname(notebook_path))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
