{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\data\\txt\\gradient.txt\n",
      "\\b(ChoroplethUtilities|NotebookUtilities|StatsChartingUtilities|StatsScrapingUtilities|__builtins__|__cached__|__doc__|__file__|__loader__|__name__|__package__|__path__|__spec__|all_countries_df|choropleth_utils|cu|notebook_utils|nu|osp|scu|ssu|stats_charting_utils|stats_scraping_utils|us_stats_df)\\b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import os.path as osp\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import platform\n",
    "import sys\n",
    "# import tensorflow\n",
    "# import datetime\n",
    "sys.path.insert(1, osp.abspath('../py'))\n",
    "from StatsByCountry import nu, cu, scu, ssu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nu.open_path_in_notepad('~\\OneDrive\\Documents\\GitHub\\StatsByCountry\\py\\StatsByCountry\\choropleth_utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for *.ipynb; file masks in the C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry folder for this pattern:\n",
      "\\s+\"def (my_function)\\(\n",
      "Replace each of the calls to these definitions with calls the the nu. equivalent (and delete the definitions).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nu.show_duplicated_util_fns_search_string(util_path=None, github_folder=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\AppData\\Local\\Temp\\ipykernel_15036\\1516887960.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def my_function(): pass\n",
    "file_path = nu.get_function_file_path(my_function)\n",
    "print(os.path.abspath(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anaconda_folder', 'bin_folder', 'cache_folder', 'data_csv_folder', 'data_folder', 'data_models_folder', 'db_folder', 'graphs_folder', 'indices_folder', 'saves_csv_folder', 'saves_folder', 'saves_mp3_folder', 'saves_pickle_folder', 'saves_text_folder', 'saves_wav_folder', 'scripts_folder', 'txt_folder']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[fn for fn in dir(nu) if fn.endswith('_folder')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\WD Backup.swstor\\\\daveb\\\\OWRlZGNiNzhiZmZlNDQ0Ym\\\\Volume{b1738a0e-843d-405c-b5ed-240d0e1ede23}\\\\Users\\\\daveb\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Default\\\\Extensions\\\\bkdgflcldnnnapblkhphbgpggdiikppg\\\\2022.12.12_0\\\\dashboard\\\\img\\\\refresh-assets\\\\back-arrow-android--light.svg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.svg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      9\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sub_directory, file_name)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<image\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, f\u001b[38;5;241m.\u001b[39mread()):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\WD Backup.swstor\\\\daveb\\\\OWRlZGNiNzhiZmZlNDQ0Ym\\\\Volume{b1738a0e-843d-405c-b5ed-240d0e1ede23}\\\\Users\\\\daveb\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Default\\\\Extensions\\\\bkdgflcldnnnapblkhphbgpggdiikppg\\\\2022.12.12_0\\\\dashboard\\\\img\\\\refresh-assets\\\\back-arrow-android--light.svg'"
     ]
    }
   ],
   "source": [
    "\n",
    "# black_list = ['.ipynb_checkpoints', '$RECYCLE.BIN', '$Recycle.Bin', '.git', 'load_magic', 'flags', 'emblems', 'maps']\n",
    "black_list = ['.ipynb_checkpoints', '$RECYCLE.BIN', '$Recycle.Bin', '.git', 'load_magic']\n",
    "file_paths_dict = {}\n",
    "for root_dir in ['C:\\\\', 'D:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if file_name.endswith('.svg'):\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        try:\n",
    "                            if not re.search(r'<image\\s+', f.read()):\n",
    "                                file_paths_list = file_paths_dict.get(sub_directory, [])\n",
    "                                file_paths_list.append(file_name)\n",
    "                                file_paths_dict[sub_directory] = file_paths_list\n",
    "                        except:\n",
    "                            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted([(sub_directory, file_paths_list) for sub_directory, file_paths_list in file_paths_dict.items()], key=lambda x: len(x[1]), reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "sys.path.insert(1, '../py')\n",
    "from choropleth_utils import ChoroplethUtilities\n",
    "from stats_scraping_utils import StatsScrapingUtilities\n",
    "from storage import Storage\n",
    "import numpy as np\n",
    "\n",
    "s = Storage()\n",
    "ssu = StatsScrapingUtilities(s=s)\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\gpt-stuff\\ps1\\create_temp_environment_yml_file.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\ps1\\create_temp_environment_yml_file.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\notebooks\\ps1\\create_temp_environment_yml_file.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\ps1\\create_temp_environment_yml_file.ps1\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\test\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\backups\\dev\\Documents\\Repositories\\job-hunting\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\backups\\dev\\Documents\\Repositories\\notebooks\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\backups\\dev\\Documents\\Repositories\\rpc\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\job-hunting\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\job-hunting_old\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\notebooks\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\notebooks_old\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\rpc\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\rpc_old\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\space-track-scenario\\ps1\\create_temp_environment_yml_file.ps1\n",
      "D:\\Geek Squad Data Backup\\HDD\\Documents\\GitHub\\test\\ps1\\create_temp_environment_yml_file.ps1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extensions_list = ['.png', '.jpg', '.gif']\n",
    "for root_dir in ['C:\\\\', 'D:\\\\']:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "            for file_name in files_list:\n",
    "                if ('create_temp_environment_yml_file.ps1' == file_name):\n",
    "                    file_path = os.path.join(sub_directory, file_name)\n",
    "                    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Inkscape\n",
      "C:\\Program Files\\Inkscape\\share\\inkscape\n",
      "C:\\Program Files\\Inkscape\\share\\inkscape\\themes\\Minwaita-Inkscape\n",
      "C:\\Program Files\\Inkscape\\share\\inkscape\\themes\\Minwaita-Inkscape-Dark\n",
      "C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Inkscape\n",
      "C:\\texlive\\2022\\texmf-dist\\doc\\latex\\svg-inkscape\n",
      "C:\\Users\\daveb\\AppData\\Local\\Microsoft\\Windows\\INetCache\\inkscape\n",
      "C:\\Users\\daveb\\AppData\\Roaming\\inkscape\n",
      "C:\\Users\\daveb\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\7bhtbd98.default-release\\storage\\default\\https+++inkscape.org\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\\\'):\n",
    "    if ('inkscape' in sub_directory.split(os.sep)[-1].lower()):\n",
    "        print(sub_directory.replace('\\\\\\\\', '\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.load_object('all_countries_df')\n",
      "s.load_object('country_stats_df')\n",
      "s.load_object('eurasia_df')\n",
      "s.load_object('wikipedia_country_border_summaries_df')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(s.saves_pickle_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.lower().endswith('_df.pkl'):\n",
    "                pickle_name = file_name.split('.')[0]\n",
    "                eval_str = f\"s.load_object('{pickle_name}')\"\n",
    "                df = eval(eval_str)\n",
    "                if ('wikipedia_title' in df.columns):\n",
    "                    print(eval_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the path tags that are associated with the France district\n",
    "saves_svg_folder = os.path.abspath('../saves/svg')\n",
    "for sub_directory, directories_list, files_list in os.walk(saves_svg_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.lower().endswith('.svg'):\n",
    "                file_path = os.path.join(saves_svg_folder, file_name)\n",
    "                page_soup = ssu.get_page_soup(file_path, verbose=True)\n",
    "                g_soups_list = page_soup.find_all('g', id='France_mainland')\n",
    "                if g_soups_list:\n",
    "                    print(file_name, len(g_soups_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF_city_equivalent_gdp.svg 1\n",
      "AF_codes_state_equivalent_district_abbreviation.svg 1\n",
      "AF_district_abbreviation.svg 1\n",
      "AF_log_pwrindx_score_district_abbreviation.svg 1\n",
      "AF_log_pwrindx_score_wikipedia_title.svg 1\n",
      "AF_log_pwrindx_score_wikipedia_title_save_a_copy.svg 1\n",
      "AF_pwrindx_score_district_abbreviation.svg 1\n",
      "AF_state_equivalent.svg 1\n",
      "AF_state_equivalent_gdp.svg 1\n",
      "AF_state_equivalent_military_expenditure.svg 1\n",
      "AF_state_equivalent_military_expenditure_save_a_copy.svg 1\n",
      "AF_state_equivalent_plane.svg 1\n",
      "AF_state_equivalent_save_a_copy.svg 1\n",
      "AF_year_code_established.svg 1\n",
      "US_codes_state_equivalent.svg 1\n",
      "US_codes_state_equivalent_state_equivalent_saved.svg 1\n",
      "US_year_code_established.svg 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the path tags that are associated with the France district\n",
    "saves_svg_folder = os.path.abspath('../saves/svg')\n",
    "for sub_directory, directories_list, files_list in os.walk(saves_svg_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.lower().endswith('.svg'):\n",
    "                file_path = os.path.join(saves_svg_folder, file_name)\n",
    "                page_soup = ssu.get_page_soup(file_path, verbose=True)\n",
    "                g_soups_list = page_soup.find_all('path', id='district-france')\n",
    "                if g_soups_list:\n",
    "                    print(file_name, len(g_soups_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlankMap-World.svg 244\n",
      "BlankMap-World_old.svg 171\n",
      "BlankMap-World_optimized.svg 171\n",
      "BlankMap-World_optimized_save_as.svg 171\n",
      "BlankMap-World_outerHTML.svg 244\n",
      "BlankMap-World_save_as.svg 244\n",
      "BlankMap-World_save_as_titled.svg 244\n",
      "Political_map_world_1986-1989_Dutch.svg 1\n",
      "Political_map_world_1986-1989_Dutch_save_as.svg 1\n",
      "WorldMap.svg 162\n",
      "WorldMap_optimized.svg 162\n",
      "WorldMap_plain.svg 162\n",
      "WorldMap_save_as.svg 162\n",
      "WorldMap_save_a_copy.svg 162\n",
      "world_map.svg 147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the group tags that are associated with all the contries in our all-countries dataset\n",
    "all_countries_df = s.load_object('all_countries_df')\n",
    "codes_list = [cc.lower() for cc in all_countries_df.country_code]\n",
    "codes_regex = re.compile('^(' + '|'.join(codes_list) + ')$')\n",
    "\n",
    "saves_svg_folder = os.path.abspath('../saves/svg')\n",
    "for sub_directory, directories_list, files_list in os.walk(saves_svg_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.lower().endswith('.svg'):\n",
    "                file_path = os.path.join(saves_svg_folder, file_name)\n",
    "                page_soup = ssu.get_page_soup(file_path, verbose=True)\n",
    "                g_soups_list = page_soup.find_all('g', id=codes_regex)\n",
    "                if g_soups_list:\n",
    "                    print(file_name, len(g_soups_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk('../../'):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.lower().endswith('.mov'):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk('../'):\n",
    "    if (not '_old' in sub_directory) and all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if file_name.lower().endswith('.svg') and (not 'Afghanistan' in file_name) and (not file_name.startswith('AF_')):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\300d\\glove.840B.300d.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.100d.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.200d.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.50d.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\zip\\glove.6B.zip\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\zip\\glove.840B.300d.zip\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\flaskr\\saves\\pkl\\GLOVE_BIG.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\flaskr\\saves\\pkl\\GLOVE_SMALL.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Lib\\site-packages\\gensim\\scripts\\glove2word2vec.py\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Lib\\site-packages\\gensim\\scripts\\__pycache__\\glove2word2vec.cpython-37.pyc\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Lib\\site-packages\\gensim\\test\\test_glove2word2vec.py\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Lib\\site-packages\\gensim\\test\\test_data\\test_glove.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\jh_env\\Lib\\site-packages\\gensim\\test\\__pycache__\\test_glove2word2vec.cpython-37.pyc\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\GLOVE_BIG.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\saves\\pkl\\GLOVE_SMALL.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\notebooks\\saves\\pkl\\glove_english_five_letter_words_list.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\flaskr\\saves\\pkl\\GLOVE_BIG.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\flaskr\\saves\\pkl\\GLOVE_SMALL.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\sts\\Lib\\site-packages\\gensim\\scripts\\glove2word2vec.py\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\sts\\Lib\\site-packages\\gensim\\scripts\\__pycache__\\glove2word2vec.cpython-37.pyc\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\sts\\Lib\\site-packages\\gensim\\test\\test_glove2word2vec.py\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\sts\\Lib\\site-packages\\gensim\\test\\test_data\\test_glove.txt\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\sts\\Lib\\site-packages\\gensim\\test\\__pycache__\\test_glove2word2vec.cpython-37.pyc\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Wordle\\saves\\pkl\\glove_english_five_letter_words_list.pkl\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\Python Scripts\\py\\glove2word2vec.ZCQHSN.py\n",
      "C:\\\\Users\\daveb\\OneDrive\\Documents\\Python Scripts\\py\\test_glove2word2vec.PZXLAF.py\n",
      "C:\\\\Windows\\servicing\\LCU\\Package_for_RollupFix~31bf3856ad364e35~amd64~~22000.318.1.8\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\f\\autopilotwhiteglovelanding-main.html\n",
      "C:\\\\Windows\\servicing\\LCU\\Package_for_RollupFix~31bf3856ad364e35~amd64~~22000.318.1.8\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\f\\autopilotwhiteglovelanding-page.js\n",
      "C:\\\\Windows\\servicing\\LCU\\Package_for_RollupFix~31bf3856ad364e35~amd64~~22000.318.1.8\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\f\\autopilotwhiteglovelanding-vm.js\n",
      "C:\\\\Windows\\servicing\\LCU\\Package_for_RollupFix~31bf3856ad364e35~amd64~~22000.318.1.8\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\f\\autopilotwhitegloveresult-main.html\n",
      "C:\\\\Windows\\servicing\\LCU\\Package_for_RollupFix~31bf3856ad364e35~amd64~~22000.318.1.8\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\f\\autopilotwhitegloveresult-page.js\n",
      "C:\\\\Windows\\servicing\\LCU\\Package_for_RollupFix~31bf3856ad364e35~amd64~~22000.318.1.8\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\f\\autopilotwhitegloveresult-vm.js\n",
      "C:\\\\Windows\\SystemApps\\Microsoft.Windows.CloudExperienceHost_cw5n1h2txyewy\\webapps\\inclusiveOobe\\js\\autopilotwhiteglovelanding-page.js\n",
      "C:\\\\Windows\\SystemApps\\Microsoft.Windows.CloudExperienceHost_cw5n1h2txyewy\\webapps\\inclusiveOobe\\js\\autopilotwhiteglovelanding-vm.js\n",
      "C:\\\\Windows\\SystemApps\\Microsoft.Windows.CloudExperienceHost_cw5n1h2txyewy\\webapps\\inclusiveOobe\\js\\autopilotwhitegloveresult-page.js\n",
      "C:\\\\Windows\\SystemApps\\Microsoft.Windows.CloudExperienceHost_cw5n1h2txyewy\\webapps\\inclusiveOobe\\js\\autopilotwhitegloveresult-vm.js\n",
      "C:\\\\Windows\\SystemApps\\Microsoft.Windows.CloudExperienceHost_cw5n1h2txyewy\\webapps\\inclusiveOobe\\view\\autopilotwhiteglovelanding-main.html\n",
      "C:\\\\Windows\\SystemApps\\Microsoft.Windows.CloudExperienceHost_cw5n1h2txyewy\\webapps\\inclusiveOobe\\view\\autopilotwhitegloveresult-main.html\n",
      "C:\\\\Windows\\WinSxS\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\autopilotwhiteglovelanding-main.html\n",
      "C:\\\\Windows\\WinSxS\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\autopilotwhiteglovelanding-page.js\n",
      "C:\\\\Windows\\WinSxS\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\autopilotwhiteglovelanding-vm.js\n",
      "C:\\\\Windows\\WinSxS\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\autopilotwhitegloveresult-main.html\n",
      "C:\\\\Windows\\WinSxS\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\autopilotwhitegloveresult-page.js\n",
      "C:\\\\Windows\\WinSxS\\amd64_microsoft-windows-management-oobe_31bf3856ad364e35_10.0.22000.71_none_5465725c68e2919e\\autopilotwhitegloveresult-vm.js\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\\\'):\n",
    "    if (not '_old' in sub_directory) and all(map(lambda x: x not in sub_directory, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if 'glove' in file_name.lower():\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "column_descriptions_df = s.load_object('column_descriptions_df')\n",
      "['column_name', 'dtype', 'count_blanks', 'count_uniques', 'count_zeroes', 'has_dates', 'min_value', 'max_value', 'only_integers']\n",
      "\n",
      "gdp_df = s.load_object('gdp_df')\n",
      "['Ethnic_diversity_rank', 'Ethnic_fractionalization_index', 'Cultural_diversity_index', 'Fractionalization_rank', 'Ethnic_fractionalization', 'Linguistic_fractionalization', 'Religious_fractionalization', 'Murder_rate', 'Murder_count', 'Region', 'Subregion', 'Year_listed', 'UNODC_notes', 'Gun_rank', 'Guns_per_100_residents', 'Karp_notes', 'Region_code', 'Subregion_code', 'IQ_Rank', 'IQ', 'CC_EST', 'CC_NO_SRC', 'CC_PER_RNK', 'CC_PER_RNK_LOWER', 'CC_PER_RNK_UPPER', 'CC_STD_ERR', 'GE_EST', 'GE_NO_SRC', 'GE_PER_RNK', 'GE_PER_RNK_LOWER', 'GE_PER_RNK_UPPER', 'GE_STD_ERR', 'PV_EST', 'PV_NO_SRC', 'PV_PER_RNK', 'PV_PER_RNK_LOWER', 'PV_PER_RNK_UPPER', 'PV_STD_ERR', 'RQ_EST', 'RQ_NO_SRC', 'RQ_PER_RNK', 'RQ_PER_RNK_LOWER', 'RQ_PER_RNK_UPPER', 'RQ_STD_ERR', 'RL_EST', 'RL_NO_SRC', 'RL_PER_RNK', 'RL_PER_RNK_LOWER', 'RL_PER_RNK_UPPER', 'RL_STD_ERR', 'VA_EST', 'VA_NO_SRC', 'VA_PER_RNK', 'VA_PER_RNK_LOWER', 'VA_PER_RNK_UPPER', 'VA_STD_ERR', 'GDP_per_capita']\n",
      "\n",
      "gun_stats_df = s.load_object('gun_stats_df')\n",
      "['Ethnic_diversity_rank', 'Ethnic_fractionalization_index', 'Cultural_diversity_index', 'Fractionalization_rank', 'Ethnic_fractionalization', 'Linguistic_fractionalization', 'Religious_fractionalization', 'Murder_rate', 'Murder_count', 'Region', 'Subregion', 'Year_listed', 'UNODC_notes', 'Gun_rank', 'Guns_per_100_residents', 'Karp_notes', 'Region_code', 'Subregion_code', 'IQ_Rank', 'IQ']\n",
      "\n",
      "state_merge_df = s.load_object('state_merge_df')\n",
      "['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent', 'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score', 'Natural_Environment_Score', 'State_Abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005', 'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010', 'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'Google_Suggest_Unique', 'text_x', 'text_y', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First', 'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight', 'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability', 'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing', 'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'outline_d']\n",
      "\n",
      "us_stats_df = s.load_object('us_stats_df')\n",
      "['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent', 'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score', 'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005', 'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010', 'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'Google_Suggest_Unique', 'text_x', 'text_y', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First', 'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight', 'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability', 'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing', 'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'outline_d', 'centroid_x', 'centroid_y', 'Country_Equivalent_GDP', 'font_size', 'gdp_millions_usd_2021', 'gdp_millions_usd_2020', 'annual_change_usd', 'annual_change_percentage', 'real_gdp_growth_percentage', 'gdp_per_capita_2021', 'gdp_per_capita_2020', 'national_precentage_2021', 'national_precentage_2020', 'proportion_of_gdp_2021', 'gdp_proportion_of_military_expenditures_2021', 'Country_Equivalent_Military_Expenditure', 'state_color']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for root_dir in [s.saves_pickle_folder, s.saves_csv_folder]:\n",
    "    for sub_directory, directories_list, files_list in os.walk(root_dir):\n",
    "        if '.ipynb_checkpoints' not in sub_directory:\n",
    "            for file_name in files_list:\n",
    "                pickle_name = file_name.split('.')[0]\n",
    "                if pickle_name.endswith('_df'):\n",
    "                    file_ending = file_name.split('.')[1]\n",
    "                    if file_ending == 'pkl':\n",
    "                        eval_str = f\"s.load_object('{pickle_name}')\"\n",
    "                    elif file_ending == 'csv':\n",
    "                        eval_str = f\"s.load_csv('{pickle_name}', folder_path=s.saves_folder)\"\n",
    "                    else:\n",
    "                        continue\n",
    "                    try:\n",
    "                        df = eval(eval_str)\n",
    "                        if any(map(lambda x: 'iq' in str(x).lower(), df.columns)):\n",
    "                            print()\n",
    "                            print(f'{pickle_name} = {eval_str}')\n",
    "                            print(df.columns.tolist())\n",
    "                    except ValueError as e:\n",
    "                        print(str(e).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\daveb\\onedrive\\documents\\github\\statsbycountry\\load_magic\\storage.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "s.load_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Ignore everything in this directory\\n*\\n# Except this file\\n!.gitignore'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_obj.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_obj.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_obj.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_obj.endpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bang_regex = re.compile(r'^!', re.MULTILINE)\n",
    "readme_regex = re.compile(r'README')\n",
    "markdown_regex = re.compile(r'\\.md\\b')\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub'):\n",
    "    if all(map(lambda x: sub_directory != x, black_list)):\n",
    "        for file_name in files_list:\n",
    "            if (file_name == '.gitignore'):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # file_data = f.read()\n",
    "                    # match_obj = bang_regex.search(file_data)\n",
    "                    # if match_obj and (match_obj.start() != 0):\n",
    "                    #     print([f'match_obj.{fn}' for fn in dir(match_obj) if not fn.startswith('_')])\n",
    "                    #     raise\n",
    "                    try:\n",
    "                        file_data = f.read()\n",
    "                        match_obj = markdown_regex.search(file_data)\n",
    "                        if match_obj:\n",
    "                            print()\n",
    "                            print(file_path)\n",
    "                            display(file_data[match_obj.start()-50:match_obj.start()+50].replace('\\n', '\\\\n'))\n",
    "                    except UnicodeDecodeError as e:\n",
    "                        print(f'UnicodeDecodeError error opening {file_path}: {str(e).strip()}')\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(f'{e.__class__.__name__} error opening {file_path}: {str(e).strip()}')\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Program Files\\Inkscape'):\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith('.svg'):\n",
    "            file_path = os.path.join(sub_directory, file_name)\n",
    "            print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.53518637"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "81.720207 + 0.81497937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Date Topic Chapter(s) Teacher\n",
    "Jan 16 Nature and Extent of Divine Covenants 1-2 Matthew\n",
    "Jan 23 Unity of Divine Covenants 3 Scott\n",
    "Jan 30 Snow Cancellation\n",
    "Feb 6 Diversity of Divine Covenants 4 Matthew\n",
    "Feb 13 Covenant of Creation (Works) 5\n",
    "Feb 20 Adam: Covenant of Commencement 6\n",
    "Feb 27 Noah: Covenant of Preservation 7\n",
    "Mar 6 Abraham: Covenant of Promise 8 Mike Leigh\n",
    "Mar 13 Circumcision and Baptism – The Seal of the Abrahamic Covenant 9\n",
    "Mar 20 Moses: Covenant of Law 10\n",
    "Mar 27 Excursus – Do Covenants or Dispensations structure Scripture? 11\n",
    "Apr 3 David: Covenant of the Kingdom 12 Rob\n",
    "Apr 10 No Sunday School – Missionary Visit\n",
    "Apr 17 No Sunday School – Easter Sunday\n",
    "Apr 24 Christ: Covenant of Consummation 13 Mike Leigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "windows_user_font_dir = r'C:\\Users\\daveb\\AppData\\Local\\Microsoft\\Windows\\Fonts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sans_regex = re.compile(r'\\bsans.serif\\b')\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Program Files\\Inkscape'):\n",
    "    for file_name in files_list:\n",
    "        file_path = os.path.join(sub_directory, file_name)\n",
    "        with open(file_path, 'r') as f:\n",
    "            try:\n",
    "                file_data = f.read()\n",
    "                if sans_regex.search(file_data):\n",
    "                    print(file_path)\n",
    "            except UnicodeDecodeError as e:\n",
    "                # print(f'UnicodeDecodeError error opening {file_path}: {str(e).strip()}')\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                # print(f'{e.__class__.__name__} error opening {file_path}: {str(e).strip()}')\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.load_object('eurasia_df') (82, 63)\n",
      "s.load_object('state_merge_df') (51, 73)\n",
      "s.load_object('us_stats_df') (51, 90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pickle_name_list = []\n",
    "for sub_directory, directories_list, files_list in os.walk(s.saves_pickle_folder):\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith('_df.pkl'):\n",
    "            pickle_name = file_name.split('.')[0]\n",
    "            eval_str = f\"s.load_object('{pickle_name}')\"\n",
    "            df = eval(eval_str)\n",
    "            if 'outline_d' in df.columns:\n",
    "                print(eval_str, df.shape)\n",
    "                pickle_name_list.append(pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.load_object('all_countries_df', verbose=False) (248, 19)\n",
      "s.load_object('country_stats_df', verbose=False) (249, 8)\n",
      "s.load_object('eurasia_df', verbose=False) (82, 63)\n",
      "s.load_object('firepower_df', verbose=False) (142, 4)\n",
      "s.load_object('gdp_countries_df', verbose=False) (216, 8)\n",
      "s.load_object('military_expenditures_df', verbose=False) (141, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rows_list = []\n",
    "for sub_directory, directories_list, files_list in os.walk(s.saves_pickle_folder):\n",
    "    if '.ipynb_checkpoints' not in sub_directory:\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('_df.pkl'):\n",
    "                pickle_name = file_name.split('.')[0]\n",
    "                eval_str = f\"s.load_object('{pickle_name}', verbose=False)\"\n",
    "                try:\n",
    "                    df = eval(eval_str)\n",
    "                    if 'country_name' in df.columns:\n",
    "                        print(eval_str, df.shape)\n",
    "                        row_dict = {}\n",
    "                        row_dict['pickle_name'] = pickle_name\n",
    "                        row_dict['country_count'] = df.shape[0]\n",
    "                        row_dict['feature_count'] = df.shape[1]\n",
    "                        rows_list.append(row_dict)\n",
    "                except Exception as e:\n",
    "                    print(f'{eval_str} gets an {e.__class__.__name__} error: {str(e).strip()}')\n",
    "                    continue\n",
    "pickles_df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "set(country_stats_df.columns).intersection(set(all_countries_df.columns))\n",
      "{'country_name', 'year_code_established', 'short_form_name', 'pwrindx_rank', 'iso_3166_2', 'cc_tld', 'code_notes', 'pwrindx_score'}\n",
      "\n",
      "set(country_stats_df.columns).intersection(set(eurasia_df.columns))\n",
      "{'country_name', 'year_code_established', 'short_form_name', 'pwrindx_rank', 'iso_3166_2', 'cc_tld', 'code_notes', 'pwrindx_score'}\n",
      "\n",
      "set(country_stats_df.columns).intersection(set(firepower_df.columns))\n",
      "{'country_name', 'short_form_name', 'pwrindx_score', 'pwrindx_rank'}\n",
      "\n",
      "set(country_stats_df.columns).intersection(set(gdp_countries_df.columns))\n",
      "{'country_name'}\n",
      "\n",
      "set(country_stats_df.columns).intersection(set(military_expenditures_df.columns))\n",
      "{'country_name'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_country_count = pickles_df.country_count.max()\n",
    "mask_series = (pickles_df.country_count == max_country_count)\n",
    "master_pickle_name = pickles_df[mask_series].pickle_name.squeeze()\n",
    "exec_str = f\"{master_pickle_name} = s.load_object('{master_pickle_name}')\"\n",
    "exec(exec_str)\n",
    "mask_series = (pickles_df.pickle_name != master_pickle_name)\n",
    "for i, r in pickles_df[mask_series].iterrows():\n",
    "    print()\n",
    "    eval_str = f\"set({master_pickle_name}.columns).intersection(set({r.pickle_name}.columns))\"\n",
    "    print(eval_str)\n",
    "    exec_str = f\"{r.pickle_name} = s.load_object('{r.pickle_name}')\"\n",
    "    exec(exec_str)\n",
    "    column_set = eval(eval_str)\n",
    "    print(column_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "set(country_stats_df.country_name).symmetric_difference(set(all_countries_df.country_name))\n",
      "{'Cabo Verde'}\n",
      "\n",
      "set(country_stats_df.country_name).symmetric_difference(set(eurasia_df.country_name))\n",
      "{'Isle of Man', 'Niue', 'Gabon', 'Saint Pierre and Miquelon', 'Namibia', 'Sudan', 'Costa Rica', 'Western Sahara', 'Barbados', 'Fiji', 'Angola', 'Gambia', 'Mexico', 'Vanuatu', 'Martinique', 'Guyana', 'Uganda', 'Samoa', 'Hong Kong', 'South Africa', 'Cameroon', 'Northern Mariana Islands', 'French Southern Territories', 'Congo', 'Chile', 'Belize', 'Cayman Islands', 'Mauritius', 'Réunion', 'Montserrat', 'Sao Tome and Principe', 'Åland Islands', 'Ethiopia', 'Haiti', 'Saint Barthélemy', 'Colombia', 'New Caledonia', 'Chad', 'Dominican Republic', 'Jersey', 'Brazil', 'Saint Lucia', 'Tanzania, United Republic of', 'Holy See', 'Greenland', 'Rwanda', 'Macao', 'Suriname', 'Guatemala', 'South Georgia and the South Sandwich Islands', 'Peru', 'Congo, Democratic Republic of the', 'United States Minor Outlying Islands', 'Anguilla', 'Canada', 'Burkina Faso', 'Mozambique', 'British Indian Ocean Territory', 'Honduras', 'Sierra Leone', 'Guinea', 'Malta', 'Grenada', 'Burundi', 'Equatorial Guinea', 'Andorra', 'American Samoa', 'Nigeria', 'Saint Helena, Ascension and Tristan da Cunha', 'South Sudan', 'French Polynesia', 'Guadeloupe', 'Saint Kitts and Nevis', 'Aruba', 'Zimbabwe', 'Guam', 'Trinidad and Tobago', 'Virgin Islands (U.S.)', 'Micronesia (Federated States of)', 'Madagascar', 'Senegal', 'Puerto Rico', 'Virgin Islands (British)', 'Bonaire, Sint Eustatius and Saba', 'Mayotte', 'Palau', 'Wallis and Futuna', 'Falkland Islands (Malvinas)', 'Paraguay', 'Kiribati', 'Niger', 'Guinea-Bissau', 'Turks and Caicos Islands', 'Eritrea', 'Svalbard and Jan Mayen', 'Pitcairn', 'Nicaragua', 'Cabo Verde', 'French Guiana', 'Cocos (Keeling) Islands', 'Comoros', 'Djibouti', 'Libya', 'Saint Martin (French part)', 'Norfolk Island', 'San Marino', 'Malawi', 'Saint Vincent and the Grenadines', 'Tunisia', 'Botswana', 'Jamaica', 'Australia', 'Guernsey', 'Tuvalu', 'Curaçao', 'Venezuela (Bolivarian Republic of)', 'Cyprus', 'Mauritania', 'Zambia', 'Dominica', 'Faroe Islands', 'Bouvet Island', 'Egypt', \"Côte d'Ivoire\", 'Bahamas', 'Antarctica', 'New Zealand', 'United States of America', 'Bahrain', 'Singapore', 'Mali', 'Bermuda', 'Benin', 'Somalia', 'Kenya', 'Morocco', 'Sint Maarten (Dutch part)', 'Christmas Island', 'Cook Islands', 'Bolivia (Plurinational State of)', 'Argentina', 'Palestine, State of', 'Gibraltar', 'Central African Republic', 'Marshall Islands', 'Panama', 'Lesotho', 'Uruguay', 'Liberia', 'Eswatini', 'Maldives', 'Seychelles', 'Nauru', 'Ecuador', 'Timor-Leste', 'Ghana', 'Cuba', 'El Salvador', 'Tokelau', 'Antigua and Barbuda', 'Togo', 'Solomon Islands', 'Liechtenstein', 'Algeria', 'Monaco', 'Heard Island and McDonald Islands', 'Tonga'}\n",
      "\n",
      "set(country_stats_df.country_name).symmetric_difference(set(firepower_df.country_name))\n",
      "{'Isle of Man', 'Niue', 'Saint Pierre and Miquelon', 'Costa Rica', 'Western Sahara', 'Barbados', 'Brunei Darussalam', 'Fiji', 'Gambia', 'Vanuatu', 'Martinique', 'Guyana', 'Samoa', 'Hong Kong', 'Northern Mariana Islands', 'French Southern Territories', 'Congo', 'Belize', 'Cayman Islands', 'Mauritius', 'Réunion', 'Montserrat', 'Sao Tome and Principe', 'Åland Islands', 'Haiti', 'Saint Barthélemy', 'New Caledonia', 'Jersey', 'Saint Lucia', 'Tanzania, United Republic of', 'Holy See', 'Greenland', 'Democratic Republic of the Congo', 'Rwanda', 'Macao', 'South Georgia and the South Sandwich Islands', 'Congo, Democratic Republic of the', 'Bolivia', 'United States Minor Outlying Islands', 'Anguilla', 'British Indian Ocean Territory', 'Guinea', 'Malta', 'Grenada', 'Burundi', 'Ivory Coast', 'Equatorial Guinea', 'Andorra', 'American Samoa', 'Saint Helena, Ascension and Tristan da Cunha', 'Papua New Guinea', 'French Polynesia', 'Guadeloupe', 'Saint Kitts and Nevis', 'Aruba', 'Kosovo', 'Guam', 'Trinidad and Tobago', 'Virgin Islands (U.S.)', 'Micronesia (Federated States of)', 'Senegal', 'Puerto Rico', 'Virgin Islands (British)', 'Bonaire, Sint Eustatius and Saba', 'Mayotte', 'Palau', 'Wallis and Futuna', 'Falkland Islands (Malvinas)', 'Kiribati', 'Guinea-Bissau', 'Turks and Caicos Islands', 'United States', 'Svalbard and Jan Mayen', 'Pitcairn', 'Cabo Verde', 'French Guiana', 'Cocos (Keeling) Islands', 'Comoros', 'Djibouti', 'Saint Martin (French part)', 'Norfolk Island', 'San Marino', 'Malawi', 'Saint Vincent and the Grenadines', 'Jamaica', 'Guernsey', 'Tuvalu', 'Curaçao', 'Venezuela (Bolivarian Republic of)', 'Cyprus', 'Republic of the Congo', 'Dominica', 'Faroe Islands', 'Bouvet Island', \"Côte d'Ivoire\", 'Bahamas', 'Antarctica', 'United States of America', 'Bermuda', 'Benin', 'Sint Maarten (Dutch part)', 'Christmas Island', 'Cook Islands', 'Bolivia (Plurinational State of)', 'Palestine, State of', 'Gibraltar', 'Venezuela', 'Marshall Islands', 'Lesotho', 'Eswatini', 'Maldives', 'Seychelles', 'Nauru', 'Tanzania', 'Timor-Leste', 'Tokelau', 'Antigua and Barbuda', 'Togo', 'Solomon Islands', 'Liechtenstein', 'Monaco', 'Heard Island and McDonald Islands', 'Tonga'}\n",
      "\n",
      "set(country_stats_df.country_name).symmetric_difference(set(gdp_countries_df.country_name))\n",
      "{'Czechia', 'Palestine', 'Laos', 'Isle of Man', 'Niue', 'Russian Federation', 'Saint Pierre and Miquelon', 'Western Sahara', 'Brunei Darussalam', 'Moldova, Republic of', 'Russia', 'Martinique', 'French Southern Territories', 'Réunion', 'Viet Nam', 'Sao Tome and Principe', 'Åland Islands', 'Saint Barthélemy', 'Jersey', 'Tanzania, United Republic of', 'Holy See', 'Macao', 'South Georgia and the South Sandwich Islands', 'Congo, Democratic Republic of the', 'Bolivia', 'United States Minor Outlying Islands', 'British Indian Ocean Territory', 'Brunei', 'Korea, Republic of', 'South Korea', 'Ivory Coast', 'Saint Helena, Ascension and Tristan da Cunha', 'Guadeloupe', 'Kosovo', 'Iran', \"Lao People's Democratic Republic\", 'Virgin Islands (U.S.)', 'Micronesia (Federated States of)', 'Zanzibar', 'Virgin Islands (British)', 'Vietnam', 'Bonaire, Sint Eustatius and Saba', 'Mayotte', 'North Korea', 'Wallis and Futuna', 'Falkland Islands (Malvinas)', 'British Virgin Islands', 'United Kingdom of Great Britain and Northern Ireland', 'United States', 'Moldova', 'Taiwan', 'Svalbard and Jan Mayen', 'Pitcairn', 'Cabo Verde', 'Iran (Islamic Republic of)', 'French Guiana', 'Cocos (Keeling) Islands', 'Saint Martin (French part)', 'Norfolk Island', 'Guernsey', 'Taiwan, Province of China', 'Venezuela (Bolivarian Republic of)', 'Faroe Islands', 'Bouvet Island', \"Côte d'Ivoire\", 'São Tomé and Príncipe', 'Antarctica', 'United States of America', 'Sint Maarten (Dutch part)', 'Sint Maarten', 'Christmas Island', 'Bolivia (Plurinational State of)', 'Palestine, State of', 'Gibraltar', 'Czech Republic', 'Venezuela', 'Syrian Arab Republic', 'East Timor', 'Tanzania', 'Syria', 'Timor-Leste', 'Tokelau', 'United Kingdom', 'Micronesia', 'Cape Verde', 'DR Congo', 'Heard Island and McDonald Islands', \"Korea (Democratic People's Republic of)\", 'Macau'}\n",
      "\n",
      "set(country_stats_df.country_name).symmetric_difference(set(military_expenditures_df.country_name))\n",
      "{'Isle of Man', 'Niue', 'Saint Pierre and Miquelon', 'Costa Rica', 'Western Sahara', 'Barbados', 'Fiji', 'Gambia', 'Vanuatu', 'Martinique', 'Guyana', 'Samoa', 'Hong Kong', 'Northern Mariana Islands', 'French Southern Territories', 'Congo', 'Belize', 'Cayman Islands', 'Mauritius', 'Réunion', 'Montserrat', 'Sao Tome and Principe', 'Åland Islands', 'Haiti', 'Saint Barthélemy', 'New Caledonia', 'Jersey', 'Saint Lucia', 'Tanzania, United Republic of', 'Holy See', 'Greenland', 'Rwanda', 'Macao', 'South Georgia and the South Sandwich Islands', 'Congo, Democratic Republic of the', 'Bolivia', 'United States Minor Outlying Islands', 'Anguilla', 'British Indian Ocean Territory', 'Guinea', 'Malta', 'Grenada', 'Burundi', 'Ivory Coast', 'Equatorial Guinea', 'Andorra', 'American Samoa', 'Saint Helena, Ascension and Tristan da Cunha', 'French Polynesia', 'Guadeloupe', 'Saint Kitts and Nevis', 'Aruba', 'Guam', 'Trinidad and Tobago', 'Virgin Islands (U.S.)', 'Micronesia (Federated States of)', 'Senegal', 'Puerto Rico', 'Virgin Islands (British)', 'Bonaire, Sint Eustatius and Saba', 'Mayotte', 'Palau', 'Wallis and Futuna', 'Falkland Islands (Malvinas)', 'Kiribati', 'Niger', 'Guinea-Bissau', 'Turks and Caicos Islands', 'United States', 'Eritrea', 'Svalbard and Jan Mayen', 'Pitcairn', 'Cabo Verde', 'French Guiana', 'Cocos (Keeling) Islands', 'Comoros', 'Djibouti', 'Saint Martin (French part)', 'Norfolk Island', 'San Marino', 'Malawi', 'Saint Vincent and the Grenadines', 'Jamaica', 'Guernsey', 'Tuvalu', 'Curaçao', 'Venezuela (Bolivarian Republic of)', 'Cyprus', 'Republic of the Congo', 'Dominica', 'Faroe Islands', 'Bouvet Island', \"Côte d'Ivoire\", 'Bahamas', 'Antarctica', 'United States of America', 'Bermuda', 'Benin', 'Sint Maarten (Dutch part)', 'Christmas Island', 'Cook Islands', 'Bolivia (Plurinational State of)', 'Palestine, State of', 'Gibraltar', 'Venezuela', 'Marshall Islands', 'Lesotho', 'Eswatini', 'Maldives', 'Seychelles', 'Nauru', 'Tanzania', 'Timor-Leste', 'Tokelau', 'Antigua and Barbuda', 'Togo', 'Solomon Islands', 'Liechtenstein', 'Monaco', 'DR Congo', 'Heard Island and McDonald Islands', 'Tonga'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mask_series = (pickles_df.pickle_name != master_pickle_name)\n",
    "for i, r in pickles_df[mask_series].iterrows():\n",
    "    print()\n",
    "    eval_str = f\"set({master_pickle_name}.country_name).symmetric_difference(set({r.pickle_name}.country_name))\"\n",
    "    print(eval_str)\n",
    "    column_set = eval(eval_str)\n",
    "    print(column_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub'):\n",
    "    base_name = os.path.basename(sub_directory)\n",
    "    dir_name = os.path.dirname(sub_directory)\n",
    "    if (base_name == 'pickle') and (os.path.basename(dir_name) == 'saves') and (not '_old' in sub_directory):\n",
    "        for file_name in files_list:\n",
    "            if(file_name.endswith('.pickle')):\n",
    "                src_path = os.path.join(sub_directory, file_name)\n",
    "                dst_path = os.path.join(sub_directory, file_name.replace('.pickle', '.pkl'))\n",
    "                os.rename(src_path, dst_path)\n",
    "        os.rename(sub_directory, sub_directory.replace('pickle', 'pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting\\data\\secrets\\jh_secrets.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\job-hunting_old\\data\\secrets\\jh_secrets.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\notebooks\\data\\json\\secrets.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\RegHex\\.gf\\aws-secret-key.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\RegHex\\.gf\\facebook-secret-key.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\RegHex\\.gf\\linkedin-secret.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\RegHex\\.gf\\square-secret.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\RegHex\\.gf\\twitter-secret.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\rpc\\data\\secrets\\rpc_secrets.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\space-track-scenario\\data\\secrets\\aws_client_secrets.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\data\\secrets\\rpc_secrets.json\n",
      "C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Twitter\\data\\json\\secrets.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(r'C:\\Users\\daveb\\OneDrive\\Documents\\GitHub'):\n",
    "    if '.ipynb_checkpoints' not in sub_directory:\n",
    "        for file_name in files_list:\n",
    "            if file_name.endswith('.json') and ('secret' in file_name.lower()):\n",
    "                file_path = os.path.join(sub_directory, file_name)\n",
    "                print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_merge_df', 'us_stats_df']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pickle_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../load_magic/dataframes.py\n",
    "%run ../load_magic/paths.py\n",
    "%run ../load_magic/lists.py\n",
    "%run ../load_magic/environment.py\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "[fn for fn in dir() if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
